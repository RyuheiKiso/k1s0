# 可観測性設計

k1s0 における監視・アラート・SLO/SLA・構造化ログの仕様を定義する。
Tier アーキテクチャの詳細は [tier-architecture.md](../../architecture/overview/tier-architecture.md) を参照。

## 基本方針

- **メトリクス**: Prometheus で収集し、Grafana で可視化する
- **ログ**: JSON 構造化ログを標準とし、Loki で集約する
- **トレース**: OpenTelemetry + Jaeger で分散トレーシングを実現する
- **アラート**: Alertmanager から Microsoft Teams へ通知する
- すべてのコンポーネントは `observability` Namespace にデプロイする

---

## 詳細設計ドキュメント

各設計の詳細は以下の分割ドキュメントを参照。

| ドキュメント | 内容 |
| --- | --- |
| [可観測性-監視アラート設計.md](./監視アラート設計.md) | D-107: RED/USE メトリクス、Prometheus、Grafana、Alertmanager、Tier 別アラートルール |
| [可観測性-SLO設計.md](./SLO設計.md) | D-108: SLO/SLA 定義、SLI、エラーバジェット運用 |
| [可観測性-トレーシング設計.md](./トレーシング設計.md) | D-110: 分散トレーシング、OpenTelemetry SDK 初期化パターン |
| [可観測性-ログ設計.md](./ログ設計.md) | D-109: 構造化ログ、JSON 標準フィールド、Loki・Promtail |

---

## ローカル開発環境デプロイ手順

docker-compose の `observability` プロファイルで可観測性スタック（Jaeger, Prometheus, Grafana, Loki）をローカルにデプロイする。

### 起動方法

```bash
# インフラ + 可観測性スタックを起動
docker compose --profile infra --profile observability up -d

# 可観測性スタックのみ起動（DB 等は不要な場合）
docker compose --profile observability up -d
```

### コンポーネントとポート一覧

| コンポーネント | ホストポート | 用途                                |
| -------------- | ------------ | ----------------------------------- |
| Jaeger UI      | 16686        | 分散トレースの検索・可視化          |
| Jaeger OTLP    | 4317 (gRPC)  | OpenTelemetry トレースの受信        |
| Jaeger OTLP    | 4318 (HTTP)  | OpenTelemetry トレースの受信        |
| Prometheus     | 9090         | メトリクスの収集・クエリ            |
| Grafana        | 3200         | ダッシュボード（ログ・メトリクス・トレース統合表示） |
| Loki           | 3100         | ログの集約・クエリ                  |

### 初回セットアップ手順

1. `docker compose --profile infra --profile observability up -d` でスタックを起動
2. Grafana（`http://localhost:3200`）に `admin` / `dev` でログイン
3. Grafana プロビジョニングによりデータソースとダッシュボードが自動設定される

### ポート 3200 の理由

Grafana のデフォルトポート 3000 はフロントエンド開発サーバーと競合するため、ホストポート 3200 にマッピングしている。

### Promtail

ローカル開発環境では Promtail を省略し、`docker compose logs` で直接確認する。Kubernetes 環境では Promtail を DaemonSet として各ノードにデプロイし、Pod の stdout/stderr を Loki に転送する。ローカル向けの設定ファイルは `infra/docker/promtail/promtail-config.yaml` に参考実装として配置している。

---

## Prometheus 設定（ローカル開発環境）

ローカル開発環境用の Prometheus 設定を `infra/docker/prometheus/prometheus.yaml` に配置する。

### scrape_configs

```yaml
# infra/docker/prometheus/prometheus.yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - /etc/prometheus/recording_rules.yaml
  - /etc/prometheus/alerting_rules.yaml

scrape_configs:
  # Prometheus 自身
  - job_name: prometheus
    static_configs:
      - targets: ["localhost:9090"]

  # auth-server (Rust)
  - job_name: auth-server-rust
    static_configs:
      - targets: ["auth-rust:8080"]
        labels:
          service: auth-server
          tier: system
          lang: rust
    metrics_path: /metrics

  # config-server (Rust)
  - job_name: config-server-rust
    static_configs:
      - targets: ["config-rust:8080"]
        labels:
          service: config-server
          tier: system
          lang: rust
    metrics_path: /metrics

  # saga-server (Rust)
  - job_name: saga-server-rust
    static_configs:
      - targets: ["saga-rust:8080"]
        labels:
          service: saga-server
          tier: system
          lang: rust
    metrics_path: /metrics

  # dlq-manager (Rust)
  - job_name: dlq-manager
    static_configs:
      - targets: ["dlq-manager:8080"]
        labels:
          service: dlq-manager
          tier: system
          lang: rust
    metrics_path: /metrics

  # bff-proxy (Go)
  - job_name: bff-proxy-go
    static_configs:
      - targets: ["bff-proxy:8080"]
        labels:
          service: bff-proxy
          tier: system
          lang: go
    metrics_path: /metrics

  # Kong API Gateway
  - job_name: kong
    static_configs:
      - targets: ["kong:8001"]
    metrics_path: /metrics
```

### Recording Rules

RED メトリクスの事前集計ルール。

```yaml
# infra/docker/prometheus/recording_rules.yaml
groups:
  - name: red-recording-rules
    interval: 30s
    rules:
      # リクエストレート（サービス別）
      - record: service:http_requests:rate5m
        expr: sum(rate(http_requests_total[5m])) by (service)

      # エラーレート（サービス別）
      - record: service:http_errors:rate5m
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
          / sum(rate(http_requests_total[5m])) by (service)

      # P99 レイテンシ（サービス別）
      - record: service:http_request_duration_seconds:p99
        expr: |
          histogram_quantile(0.99,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (service, le)
          )

      # P95 レイテンシ（サービス別）
      - record: service:http_request_duration_seconds:p95
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (service, le)
          )

      # gRPC リクエストレート（サービス別）
      - record: service:grpc_requests:rate5m
        expr: sum(rate(grpc_server_handled_total[5m])) by (service, grpc_service)

      # gRPC エラーレート（サービス別）
      - record: service:grpc_errors:rate5m
        expr: |
          sum(rate(grpc_server_handled_total{grpc_code!="OK"}[5m])) by (service, grpc_service)
          / sum(rate(grpc_server_handled_total[5m])) by (service, grpc_service)

      # gRPC P99 レイテンシ
      - record: service:grpc_handling_seconds:p99
        expr: |
          histogram_quantile(0.99,
            sum(rate(grpc_server_handling_seconds_bucket[5m])) by (service, grpc_service, le)
          )

  - name: slo-recording-rules
    rules:
      - record: slo:availability:ratio
        expr: |
          sum(rate(http_requests_total{status!~"5.."}[30d])) by (namespace, service)
          / sum(rate(http_requests_total[30d])) by (namespace, service)

      - record: slo:error_budget:remaining
        expr: |
          1 - (
            (1 - slo:availability:ratio)
            / (1 - (
              label_replace(
                vector(0.9995) and on() (kube_namespace_labels{namespace="k1s0-system"})
                or vector(0.999),
                "namespace", "$1", "namespace", "(.*)"
              )
            ))
          )
```

### Alerting Rules（ローカル開発用）

```yaml
# infra/docker/prometheus/alerting_rules.yaml
groups:
  - name: local-dev-alerts
    rules:
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.job }} is down"
          description: "{{ $labels.instance }} has been unreachable for more than 1 minute"

      - alert: HighErrorRate
        expr: service:http_errors:rate5m > 0.05
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.service }} error rate > 5%"
          description: "{{ $labels.service }} の 5xx エラー率が {{ $value | humanizePercentage }} です"

      - alert: HighLatency
        expr: service:http_request_duration_seconds:p99 > 1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.service }} P99 latency > 1s"
```

---

## Grafana ダッシュボード設定（ローカル開発環境）

### プロビジョニング設定

Grafana の自動設定ファイルを `infra/docker/grafana/provisioning/` に配置する。

#### データソース設定

```yaml
# infra/docker/grafana/provisioning/datasources/datasources.yaml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: false

  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    editable: false
    jsonData:
      derivedFields:
        - datasourceUid: jaeger
          matcherRegex: '"trace_id":"([a-f0-9]+)"'
          name: TraceID
          url: '$${__value.raw}'

  - name: Jaeger
    type: jaeger
    access: proxy
    uid: jaeger
    url: http://jaeger:16686
    editable: false
```

#### ダッシュボードプロビジョニング

```yaml
# infra/docker/grafana/provisioning/dashboards/dashboard.yml
apiVersion: 1

providers:
  - name: k1s0
    orgId: 1
    folder: k1s0
    type: file
    disableDeletion: false
    editable: true
    updateIntervalSeconds: 30
    options:
      path: /var/lib/grafana/dashboards
      foldersFromFilesStructure: false
```

### System Tier Overview ダッシュボード

`infra/docker/grafana/dashboards/system-overview.json` に配置する。以下は主要パネルの PromQL 定義。

#### リクエスト率・エラー率・レイテンシ（RED）

| パネル名              | PromQL                                                                                              | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| リクエスト率          | `sum(rate(http_requests_total{tier="system"}[5m])) by (service)`                                    | Time Series   |
| エラーレート          | `service:http_errors:rate5m{service=~"auth-server\|config-server\|saga-server\|dlq-manager"}`        | Time Series   |
| P50 レイテンシ        | `histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket{tier="system"}[5m])) by (service, le))` | Time Series   |
| P95 レイテンシ        | `service:http_request_duration_seconds:p95{service=~"auth-server\|config-server\|saga-server\|dlq-manager"}` | Time Series   |
| P99 レイテンシ        | `service:http_request_duration_seconds:p99{service=~"auth-server\|config-server\|saga-server\|dlq-manager"}` | Time Series   |

#### gRPC メトリクス

| パネル名              | PromQL                                                                                              | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| gRPC リクエスト率     | `sum(rate(grpc_server_handled_total{tier="system"}[5m])) by (service, grpc_service)`                | Time Series   |
| gRPC エラーレート     | `service:grpc_errors:rate5m{service=~"auth-server\|config-server\|saga-server\|dlq-manager"}`        | Time Series   |
| gRPC P99 レイテンシ   | `service:grpc_handling_seconds:p99{service=~"auth-server\|config-server\|saga-server\|dlq-manager"}`  | Time Series   |
| gRPC ステータスコード | `sum(rate(grpc_server_handled_total{tier="system"}[5m])) by (service, grpc_code)`                   | Bar Chart     |

#### DB クエリ時間

| パネル名              | PromQL                                                                                              | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| DB クエリ P50         | `histogram_quantile(0.50, sum(rate(db_query_duration_seconds_bucket[5m])) by (le, service, table))` | Time Series   |
| DB クエリ P95         | `histogram_quantile(0.95, sum(rate(db_query_duration_seconds_bucket[5m])) by (le, service, table))` | Time Series   |
| DB クエリ P99         | `histogram_quantile(0.99, sum(rate(db_query_duration_seconds_bucket[5m])) by (le, service, table))` | Time Series   |
| DB クエリ数           | `sum(rate(db_query_duration_seconds_count[5m])) by (service, query_name)`                           | Time Series   |

#### Kafka メッセージ数

| パネル名              | PromQL                                                                                              | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| メッセージ生成レート  | `sum(rate(kafka_messages_produced_total[5m])) by (service, topic)`                                  | Time Series   |
| メッセージ消費レート  | `sum(rate(kafka_messages_consumed_total[5m])) by (service, topic, consumer_group)`                  | Time Series   |

#### サービスヘルス

| パネル名              | PromQL                                                                                              | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| Service Up/Down       | `up{job=~"auth-server.*\|config-server.*\|saga-server.*\|dlq-manager.*\|bff-proxy.*\|kong"}`         | Stat          |

### k1s0 Overview ダッシュボード

`infra/docker/grafana/dashboards/k1s0-overview.json` に配置する。全 Tier を横断したリクエストメトリクスとリソース使用率を表示する。

| パネル名              | PromQL                                                                                              | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| Request Rate          | `rate(http_requests_total[5m])`                                                                     | Time Series   |
| Error Rate            | `rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])`                      | Time Series   |
| P50 Latency           | `histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))`             | Time Series   |
| P95 Latency           | `histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))`             | Time Series   |
| P99 Latency           | `histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))`             | Time Series   |
| Pod CPU Usage         | `rate(container_cpu_usage_seconds_total{namespace=~"k1s0-.*"}[5m])`                                | Gauge         |
| Pod Memory Usage      | `container_memory_working_set_bytes{namespace=~"k1s0-.*"} / container_spec_memory_limit_bytes`     | Gauge         |

### k1s0 Service Detail ダッシュボード

`infra/docker/grafana/dashboards/k1s0-service.json` に配置する。テンプレート変数 `$namespace` と `$service` でフィルタリングし、個別サービスの詳細メトリクスを表示する。

| パネル名                    | PromQL                                                                                              | 可視化タイプ  |
| --------------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| Request Rate by Service     | `rate(http_requests_total{namespace=~"$namespace", service=~"$service"}[5m])`                       | Time Series   |
| Error Rate by Service       | `rate(http_requests_total{namespace=~"$namespace", service=~"$service", status=~"5.."}[5m]) / rate(http_requests_total{namespace=~"$namespace", service=~"$service"}[5m])` | Time Series   |
| gRPC Request Rate           | `rate(grpc_server_handled_total{grpc_service=~"$service"}[5m])`                                    | Time Series   |
| gRPC Latency (P99)          | `histogram_quantile(0.99, sum(rate(grpc_server_handling_seconds_bucket{grpc_service=~"$service"}[5m])) by (le))` | Time Series   |
| Database Query Duration (P99) | `histogram_quantile(0.99, sum(rate(db_query_duration_seconds_bucket{service=~"$service"}[5m])) by (le))` | Time Series   |
| Kafka Messages Produced     | `rate(kafka_messages_produced_total{service=~"$service"}[5m])`                                     | Time Series   |
| Kafka Messages Consumed     | `rate(kafka_messages_consumed_total{service=~"$service"}[5m])`                                     | Time Series   |
| Pod CPU Usage               | `rate(container_cpu_usage_seconds_total{namespace=~"$namespace", pod=~"$service.*"}[5m])`          | Time Series   |

---

## Loki + Promtail 設定

### ローカル開発環境（docker-compose）

ローカルでは Loki のみ起動し、Promtail は省略する。アプリケーションのログは `docker compose logs` で直接確認する。

#### Loki 設定

```yaml
# infra/docker/loki/loki-config.yaml
auth_enabled: false

server:
  http_listen_port: 3100

common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
  ring:
    instance_addr: 127.0.0.1
    kvstore:
      store: inmemory

schema_config:
  configs:
    - from: 2024-01-01
      store: tsdb
      object_store: filesystem
      schema: v13
      index:
        prefix: index_
        period: 24h

limits_config:
  retention_period: 168h  # 7日（ローカル開発用）
  # staging: 720h (30日), prod: 2160h (90日) -- 詳細はログ設計.md の「ログ保持期間ポリシー」参照

storage_config:
  filesystem:
    directory: /loki/storage
```

#### ログラベル設計

| ラベル        | 説明                               | 例                       |
| ------------- | ---------------------------------- | ------------------------ |
| `service`     | サービス名                         | `auth-server`            |
| `tier`        | Tier 階層                          | `system`                 |
| `environment` | 環境名                             | `dev`                    |
| `level`       | ログレベル                         | `info`, `error`          |
| `trace_id`    | 分散トレースの Trace ID            | `abc123def456`           |

### Kubernetes 環境（Promtail）

Kubernetes 環境では Promtail が DaemonSet として各ノードにデプロイされ、Pod の stdout/stderr を収集する。設定は [可観測性-ログ設計.md](./ログ設計.md) の「ログ集約（Loki）」セクションを参照。

---

## Jaeger 分散トレース設定

### ローカル開発環境

ローカルでは `jaegertracing/all-in-one` で Collector・Query・UI を単一コンテナ提供する。

### OpenTelemetry Collector 設定（Kubernetes 環境向け）

Kubernetes 環境では OpenTelemetry Collector でサンプリング・バッチ処理を集中管理する。

```yaml
# otel-collector-config.yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    timeout: 5s
    send_batch_size: 512
  # テールベースサンプリング: エラーが含まれるトレースは必ず保持
  tail_sampling:
    decision_wait: 10s
    policies:
      - name: error-policy
        type: status_code
        status_code:
          status_codes: [ERROR]
      - name: rate-limiting
        type: probabilistic
        probabilistic:
          sampling_percentage: 10

exporters:
  otlp/jaeger:
    endpoint: jaeger-collector:4317
    tls:
      insecure: true
  prometheus:
    endpoint: 0.0.0.0:8889
    namespace: otel

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch, tail_sampling]
      exporters: [otlp/jaeger]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [prometheus]
```

### トレースサンプリング戦略

| 環境    | サンプリング方式              | サンプリング率 |
| ------- | ----------------------------- | -------------- |
| dev     | AlwaysOn                      | 100%           |
| staging | TraceIDRatioBased             | 50%            |
| prod    | Tail-based (OTel Collector)   | 10% + エラー 100% |

### サンプリング戦略の設計背景

- **dev**: 全トレースを記録し、デバッグ効率を最大化
- **staging**: 半数をサンプリングし、パフォーマンスへの影響を抑制
- **prod**: OTel Collector のテールベースサンプリングにより、エラーを含むトレースは必ず保持しつつ、全体量を削減

### サービスマップの活用

```
[Flutter Client] --> [Kong API Gateway] --> [auth-server] --> [Keycloak]
                                        --> [config-server] --> [PostgreSQL]
                                                            --> [Kafka]
```

Jaeger UI のサービスマップ機能により、サービス間の依存関係とレイテンシを可視化できる。各サービスの OpenTelemetry SDK がトレースコンテキストを伝搬することで、リクエスト全体のフローを追跡可能にする。

---

## アラート設定（ローカル開発環境）

### 通知先設計

| 環境    | 通知先                          | 方式                                           |
| ------- | ------------------------------- | ---------------------------------------------- |
| dev     | Prometheus UI で確認            | Alertmanager 不要                              |
| staging | Teams Webhook (dev チャネル)       | Alertmanager → prometheus-msteams           |
| prod    | Teams Webhook (運用チャネル)    | Alertmanager → prometheus-msteams              |

### アラートルール一覧

> 以下のアラートルールはローカル開発用（`infra/docker/prometheus/alerting_rules.yaml`）と Kubernetes 本番用（`infra/observability/prometheus/alerts/`）に分かれている。ローカル用は3件のみ（ServiceDown, HighErrorRate, HighLatency）で、Tier 別アラートと SLO バーンレートは Kubernetes 環境で適用する。

| アラート名                     | 条件                                                    | for  | severity | 対象 Tier            |
| ------------------------------ | ------------------------------------------------------- | ---- | -------- | -------------------- |
| SystemServiceErrorRateWarning  | system Tier 5xx エラー率 > 0.1%（5分間）                | 5m   | warning  | system               |
| SystemServiceHighErrorRate     | system Tier 5xx エラー率 > 1%（5分間）                  | 5m   | critical | system               |
| SystemServiceHighLatency       | system Tier P99 レイテンシ > 500ms（5分間）             | 5m   | warning  | system               |
| ServiceErrorRateWarning        | business/service Tier 5xx エラー率 > 0.2%（5分間）      | 5m   | warning  | business / service   |
| ServiceHighErrorRate           | business/service Tier 5xx エラー率 > 5%（5分間）        | 5m   | critical | business / service   |
| ServiceHighLatency             | business/service Tier P99 レイテンシ > 1s（5分間）      | 5m   | warning  | business / service   |
| ServiceDown（ローカル用）      | ターゲットが 1 分間 DOWN                                | 1m   | warning  | 全 Tier              |
| HighErrorRate（ローカル用）    | エラー率 > 5%（2分間）                                  | 2m   | warning  | 全 Tier              |
| HighLatency（ローカル用）      | P99 レイテンシ > 1s（2分間）                            | 2m   | warning  | 全 Tier              |
| SLOBurnRateCritical            | バーンレート > 14.4x（1h + 5m 窓）                     | 2m   | critical | 全 Tier              |
| SLOBurnRateWarning             | バーンレート > 6x（6h + 30m 窓）                       | 5m   | warning  | 全 Tier              |

---

## テレメトリライブラリとの接続設定

各言語のテレメトリライブラリは、OpenTelemetry SDK によるトレース送信と Prometheus メトリクスの公開を統一的に行う。

### 環境変数

`config.yaml` の `observability` セクションが優先。環境変数はフォールバック。k1s0 では環境変数よりも `config.yaml` の設定を優先する設計とする。環境変数は config.yaml が読み込めない場合のフォールバックとして機能する。これにより、設定の一元管理と可読性を確保しつつ、コンテナ環境でのオーバーライドも可能にしている。

| 環境変数                       | 説明                              | dev 環境デフォルト値      |
| ------------------------------ | --------------------------------- | ------------------------- |
| `OTEL_EXPORTER_OTLP_ENDPOINT` | OTLP エクスポータのエンドポイント | `http://jaeger:4317`      |
| `OTEL_SERVICE_NAME`           | サービス名                        | config.yaml の `app.name` |
| `OTEL_TRACES_SAMPLER`         | サンプラー種別                    | `always_on`               |
| `OTEL_TRACES_SAMPLER_ARG`     | サンプラー引数（ratio 等）        | `1.0`                     |

### config.yaml の observability セクション

```yaml
# config/config.dev.yaml（ローカル開発用）
observability:
  log:
    level: "debug"
    format: "text"       # dev 環境では可読性を優先し text フォーマット（ログ設計.md 参照）
  trace:
    enabled: true
    endpoint: "jaeger:4317"    # docker-compose サービス名
    sample_rate: 1.0           # dev: 100%
  metrics:
    enabled: true
    path: "/metrics"
```

```yaml
# config/config.staging.yaml（ステージング用）
observability:
  log:
    level: "info"
    format: "json"
  trace:
    enabled: true
    endpoint: "jaeger.observability.svc.cluster.local:4317"
    sample_rate: 0.5       # staging: 50%（TraceIDRatioBased）
  metrics:
    enabled: true
    path: "/metrics"
```

```yaml
# config/config.yaml（本番用デフォルト）
observability:
  log:
    level: "warn"
    format: "json"
  trace:
    enabled: true
    endpoint: "jaeger.observability.svc.cluster.local:4317"
    sample_rate: 0.1       # prod: 10%（Collector でテールベースサンプリング）
  metrics:
    enabled: true
    path: "/metrics"
```

### 言語別テレメトリライブラリの初期化

#### Go

```go
import "github.com/k1s0-platform/system-library-go-telemetry"

cfg := telemetry.TelemetryConfig{
    ServiceName:   "auth-server",
    Version:       "1.0.0",
    Tier:          "system",
    Environment:   "dev",
    TraceEndpoint: "jaeger:4317",    // OTLP gRPC
    SampleRate:    1.0,
    LogLevel:      "debug",
    LogFormat:     "text",           // dev 環境では可読性を優先し text フォーマット（ログ設計.md 参照）
}
provider, err := telemetry.InitTelemetry(ctx, cfg)
defer provider.Shutdown(ctx)

// メトリクス
metrics := telemetry.NewMetrics("auth-server")
http.Handle("/metrics", telemetry.MetricsHandler())
```

#### Rust

```rust
use k1s0_telemetry::{TelemetryConfig, init_telemetry, metrics::Metrics};

let cfg = TelemetryConfig {
    service_name: "auth-server".into(),
    version: "1.0.0".into(),
    tier: "system".into(),
    environment: "dev".into(),
    trace_endpoint: Some("http://jaeger:4317".into()),
    sample_rate: 1.0,
    log_level: "debug".into(),
    log_format: "text".into(),    // dev 環境では可読性を優先し text フォーマット
};
init_telemetry(&cfg)?;

let metrics = Metrics::new("auth-server");
// axum: .route("/metrics", get(|| async { metrics.gather_metrics() }))
```

#### TypeScript

```typescript
import { initTelemetry, TelemetryConfig, Metrics } from '@k1s0/telemetry';

const config: TelemetryConfig = {
  serviceName: 'bff-server',
  version: '1.0.0',
  tier: 'system',
  environment: 'dev',
  traceEndpoint: 'http://jaeger:4317',
  sampleRate: 1.0,
  logLevel: 'debug',
  logFormat: 'text',
};
initTelemetry(config);

const metrics = new Metrics('bff-server');
// Express: app.get('/metrics', (req, res) => res.send(metrics.getMetrics()));
```

#### Dart（Flutter）

```dart
import 'package:k1s0_telemetry/telemetry.dart';

final config = TelemetryConfig(
  serviceName: 'flutter-client',
  version: '1.0.0',
  tier: 'service',
  environment: 'dev',
  logLevel: 'debug',
  logFormat: 'text',
  // traceEndpoint: null,  // OpenTelemetry トレースエンドポイント（現時点では未対応）
  // sampleRate: 1.0,      // トレースサンプリングレート（デフォルト: 1.0）
);
initTelemetry(config);

final metrics = Metrics(serviceName: 'flutter-client');
```

> **Dart 制約**: Dart テレメトリライブラリは構造化ログとメトリクス計測を提供するが、OpenTelemetry トレースの送信は現時点では未対応。Flutter クライアントのトレースは HTTP ヘッダ経由でサーバー側トレースと相関させる。

---

## カスタムメトリクス一覧

全サーバーが `/metrics` エンドポイントで公開するメトリクスの一覧。テレメトリライブラリ（Go / Rust / TypeScript / Dart）が提供する共通メトリクスと、サーバー固有のカスタムメトリクスに分類する。

### 共通メトリクス（テレメトリライブラリ提供）

| メトリクス名                      | 型        | ラベル                                      | 説明                                       |
| --------------------------------- | --------- | ------------------------------------------- | ------------------------------------------ |
| `http_requests_total`             | counter   | `service`, `method`, `path`, `status`       | HTTP リクエスト総数                        |
| `http_request_duration_seconds`   | histogram | `service`, `method`, `path`                 | HTTP リクエストのレイテンシ（バケット: 5ms〜10s） |
| `grpc_server_handled_total`       | counter   | `service`, `grpc_service`, `grpc_method`, `grpc_code` | gRPC リクエスト完了数                |
| `grpc_server_handling_seconds`    | histogram | `service`, `grpc_service`, `grpc_method`    | gRPC リクエストのレイテンシ（バケット: 5ms〜10s） |

ヒストグラムバケット境界: `[0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]`（秒）

### サーバー固有メトリクス

| メトリクス名                      | 型        | ラベル                          | サーバー         | 説明                                |
| --------------------------------- | --------- | ------------------------------- | ---------------- | ----------------------------------- |
| `db_query_duration_seconds`       | histogram | `query_name`, `table`           | auth / config    | データベースクエリの実行時間        |
| `kafka_messages_produced_total`   | counter   | `topic`                         | 全 Kafka 対応サーバー※ | Kafka メッセージの送信数            |
| `kafka_messages_consumed_total`   | counter   | `topic`, `consumer_group`       | 全 Kafka 対応サーバー※ | Kafka メッセージの受信数            |
| `cache_hits_total`                | counter   | `cache_name`                    | キャッシュ対応サーバー  | キャッシュヒット数                  |
| `cache_misses_total`              | counter   | `cache_name`                    | キャッシュ対応サーバー  | キャッシュミス数                    |

> ※ **Kafka 対応サーバー**: config-server, auth-server, saga-server, notification-server, api-registry-server, featureflag-server, file-server, vault-server, quota-server, search-server, dlq-manager-server, event-store-server

> **言語別対応状況**: サーバー固有メトリクス（DB, Kafka, Cache）は **Rust テレメトリライブラリのみ**が組み込み提供する。Go / TypeScript / Dart のサーバーでは、各サーバーの実装側で `Metrics` API を使用して個別にメトリクスを定義・記録する。

### メトリクス出力対応状況

| 言語       | ライブラリパス                                        | 出力方式                  |
| ---------- | ----------------------------------------------------- | ------------------------- |
| Go         | `regions/system/library/go/telemetry/metrics.go`      | `prometheus/client_golang` → `promhttp.Handler()` |
| Rust       | `regions/system/library/rust/telemetry/src/metrics.rs` | `prometheus` crate → `TextEncoder` |
| TypeScript | `regions/system/library/typescript/telemetry/src/metrics.ts` | 独自実装 → Prometheus テキストフォーマット |
| Dart       | `regions/system/library/dart/telemetry/lib/src/metrics.dart` | 独自実装 → Prometheus テキストフォーマット |

> **ミドルウェアの自動メトリクス記録**: Rust テレメトリライブラリの HTTP/gRPC ミドルウェア（`MetricsLayer` / `GrpcMetricsLayer`）は Prometheus メトリクス（`http_requests_total`, `http_request_duration_seconds` 等）を自動記録する。Go / TypeScript のミドルウェアはトレーシングスパンと構造化ログのみを記録し、Prometheus メトリクスは `Metrics` API を使用して手動で記録する必要がある。

---

## 技術スタック選定理由

### Prometheus + Grafana

- Kubernetes エコシステムとの深い統合（ServiceMonitor, kube-state-metrics）
- PromQL による柔軟なクエリと Recording Rules による事前集計
- Grafana のデータソース統合（Prometheus, Loki, Jaeger を単一 UI で横断表示）

### Loki

- Prometheus と同じラベルベースのクエリモデルで、学習コストが低い
- ログの全文インデックスを持たない設計により、Elasticsearch 比でストレージコストが大幅に低減
- Grafana との統合により、ログからトレースへのドリルダウンが容易

### Jaeger + OpenTelemetry

- OpenTelemetry は CNCF 標準のテレメトリフレームワークで、ベンダーロックインを回避
- Jaeger は分散トレースの可視化・分析に特化し、サービスマップ機能でサービス間依存を俯瞰可能
- OTel Collector のテールベースサンプリングで、エラートレースを確実に保持しつつストレージ量を削減

## Prometheus static_configs の理由

ローカルでは `static_configs` でターゲットを直接指定する。Kubernetes 環境では ServiceMonitor を使用する。docker-compose.override.yaml で有効にしたサービスのみスクレイプ対象になる。未起動のターゲットは Prometheus 側で `DOWN` として表示されるが問題ない。

## Alertmanager 省略の理由

ローカル開発環境では Alertmanager は省略し、Prometheus UI でアラートルールの評価結果を確認する。本番環境の Alertmanager 設定は [可観測性-監視アラート設計.md](./監視アラート設計.md) の「Alertmanager → Teams 通知」セクションを参照。

## Loki → Jaeger トレース連携

Loki のログから `trace_id` を抽出し、Jaeger のトレースにドリルダウンできるように Grafana データソースの `derivedFields` を設定している。これにより、エラーログからワンクリックで該当トレースの全スパンを確認でき、障害調査の効率が大幅に向上する。

---

## 関連ドキュメント

- [可観測性-監視アラート設計.md](./監視アラート設計.md) -- D-107: 監視・アラート設計
- [可観測性-SLO設計.md](./SLO設計.md) -- D-108: SLO/SLA 定義
- [可観測性-トレーシング設計.md](./トレーシング設計.md) -- D-110: 分散トレーシング
- [可観測性-ログ設計.md](./ログ設計.md) -- D-109: 構造化ログ
- [tier-architecture.md](../../architecture/overview/tier-architecture.md) -- Tier アーキテクチャの詳細
- [kubernetes設計.md](../../infrastructure/kubernetes/kubernetes設計.md) -- Namespace・NetworkPolicy 設計
- [インフラ設計.md](../../infrastructure/overview/インフラ設計.md) -- オンプレミスインフラ構成
- [サービスメッシュ設計.md](../../infrastructure/service-mesh/サービスメッシュ設計.md) -- Istio 設計・耐障害性
- [config.md](../../cli/config/config設計.md) -- config.yaml スキーマと環境別管理
- [CI-CD設計.md](../../infrastructure/cicd/CI-CD設計.md) -- CI/CD パイプライン設計
- [helm設計.md](../../infrastructure/kubernetes/helm設計.md) -- Helm Chart 設計
- [メッセージング設計.md](../../architecture/messaging/メッセージング設計.md) -- Kafka メッセージング設計
- [APIゲートウェイ設計.md](../api/APIゲートウェイ設計.md) -- API Gateway 設計
- [docker-compose設計.md](../../infrastructure/docker/docker-compose設計.md) -- ローカル開発環境の可観測性サービス設定
- [テンプレート仕様-サーバー.md](../../templates/server/サーバー.md) -- サーバーテンプレート（OTel 初期化・構造化ログ）
