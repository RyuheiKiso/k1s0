# 可観測性設計 ガイド

> **仕様**: メトリクス定義・アラートルール・設定ファイルは [可観測性設計.md](./可観測性設計.md) を参照。

## 技術スタック選定理由

### Prometheus + Grafana

- Kubernetes エコシステムとの深い統合（ServiceMonitor, kube-state-metrics）
- PromQL による柔軟なクエリと Recording Rules による事前集計
- Grafana のデータソース統合（Prometheus, Loki, Jaeger を単一 UI で横断表示）

### Loki

- Prometheus と同じラベルベースのクエリモデルで、学習コストが低い
- ログの全文インデックスを持たない設計により、Elasticsearch 比でストレージコストが大幅に低減
- Grafana との統合により、ログからトレースへのドリルダウンが容易

### Jaeger + OpenTelemetry

- OpenTelemetry は CNCF 標準のテレメトリフレームワークで、ベンダーロックインを回避
- Jaeger は分散トレースの可視化・分析に特化し、サービスマップ機能でサービス間依存を俯瞰可能
- OTel Collector のテールベースサンプリングで、エラートレースを確実に保持しつつストレージ量を削減

## ローカル開発環境の設計背景

### ポート 3200 の理由

Grafana のデフォルトポート 3000 はフロントエンド開発サーバーと競合するため、ホストポート 3200 にマッピングしている。

### Promtail 省略の理由

ローカル開発環境では Promtail を省略している。Kubernetes 環境では Promtail（DaemonSet）がログを収集し Loki に転送するが、ローカルでは各コンテナの stdout を `docker compose logs` で確認する。Loki へのログ送信が必要な場合は、アプリケーション側で直接 Loki API にプッシュする。

### Prometheus static_configs の理由

ローカルでは `static_configs` でターゲットを直接指定する。Kubernetes 環境では ServiceMonitor を使用する。docker-compose.override.yaml で有効にしたサービスのみスクレイプ対象になる。未起動のターゲットは Prometheus 側で `DOWN` として表示されるが問題ない。

### Alertmanager 省略の理由

ローカル開発環境では Alertmanager は省略し、Prometheus UI でアラートルールの評価結果を確認する。本番環境の Alertmanager 設定は [可観測性-監視アラート設計.md](./監視アラート設計.md) の「Alertmanager → Teams 通知」セクションを参照。

## Loki → Jaeger トレース連携

Loki のログから `trace_id` を抽出し、Jaeger のトレースにドリルダウンできるように Grafana データソースの `derivedFields` を設定している。これにより、エラーログからワンクリックで該当トレースの全スパンを確認でき、障害調査の効率が大幅に向上する。

## トレースサンプリング戦略の設計背景

| 環境    | サンプリング方式              | サンプリング率 |
| ------- | ----------------------------- | -------------- |
| dev     | AlwaysOn                      | 100%           |
| staging | TraceIDRatioBased             | 50%            |
| prod    | Tail-based (OTel Collector)   | 10% + エラー 100% |

- **dev**: 全トレースを記録し、デバッグ効率を最大化
- **staging**: 半数をサンプリングし、パフォーマンスへの影響を抑制
- **prod**: OTel Collector のテールベースサンプリングにより、エラーを含むトレースは必ず保持しつつ、全体量を削減

## config.yaml 優先の設計背景

k1s0 では環境変数よりも `config.yaml` の設定を優先する設計とする。環境変数は config.yaml が読み込めない場合のフォールバックとして機能する。これにより、設定の一元管理と可読性を確保しつつ、コンテナ環境でのオーバーライドも可能にしている。

## 言語別テレメトリライブラリ初期化パターン

### Go

```go
import "github.com/k1s0/regions/system/library/go/telemetry"

cfg := telemetry.TelemetryConfig{
    ServiceName:   "auth-server",
    Version:       "1.0.0",
    Tier:          "system",
    Environment:   "dev",
    TraceEndpoint: "jaeger:4317",    // OTLP gRPC
    SampleRate:    1.0,
    LogLevel:      "debug",
}
provider, err := telemetry.InitTelemetry(ctx, cfg)
defer provider.Shutdown(ctx)

// メトリクス
metrics := telemetry.NewMetrics("auth-server")
http.Handle("/metrics", telemetry.MetricsHandler())
```

### Rust

```rust
use k1s0_telemetry::{TelemetryConfig, init_telemetry, metrics::Metrics};

let cfg = TelemetryConfig {
    service_name: "auth-server".into(),
    version: "1.0.0".into(),
    tier: "system".into(),
    environment: "dev".into(),
    trace_endpoint: Some("http://jaeger:4317".into()),
    sample_rate: 1.0,
    log_level: "debug".into(),
};
init_telemetry(&cfg)?;

let metrics = Metrics::new("auth-server");
// axum: .route("/metrics", get(|| async { metrics.gather_metrics() }))
```

### TypeScript

```typescript
import { initTelemetry, TelemetryConfig, Metrics } from '@k1s0/telemetry';

const config: TelemetryConfig = {
  serviceName: 'bff-server',
  version: '1.0.0',
  tier: 'system',
  environment: 'dev',
  traceEndpoint: 'http://jaeger:4317',
  logLevel: 'debug',
};
initTelemetry(config);

const metrics = new Metrics('bff-server');
// Express: app.get('/metrics', (req, res) => res.send(metrics.getMetrics()));
```

### Dart（Flutter）

```dart
import 'package:k1s0_telemetry/telemetry.dart';

final config = TelemetryConfig(
  serviceName: 'flutter-client',
  version: '1.0.0',
  tier: 'service',
  environment: 'dev',
  logLevel: 'debug',
);
initTelemetry(config);

final metrics = Metrics(serviceName: 'flutter-client');
```

> **Dart 制約**: Dart テレメトリライブラリは構造化ログとメトリクス計測を提供するが、OpenTelemetry トレースの送信は現時点では未対応。Flutter クライアントのトレースは HTTP ヘッダ経由でサーバー側トレースと相関させる。

## サービスマップの活用

```
[Flutter Client] --> [Kong API Gateway] --> [auth-server] --> [Keycloak]
                                        --> [config-server] --> [PostgreSQL]
                                                            --> [Kafka]
```

Jaeger UI のサービスマップ機能により、サービス間の依存関係とレイテンシを可視化できる。各サービスの OpenTelemetry SDK がトレースコンテキストを伝搬することで、リクエスト全体のフローを追跡可能にする。

## 初回セットアップ手順

1. `docker compose --profile infra --profile observability up -d` でスタックを起動
2. Grafana（`http://localhost:3200`）に `admin` / `dev` でログイン
3. Grafana プロビジョニングによりデータソースとダッシュボードが自動設定される
