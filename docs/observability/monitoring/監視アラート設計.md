# 可観測性 - 監視アラート設計

D-107: 監視・アラート設計。RED/USE メトリクス、Prometheus、Grafana、Alertmanager、Tier 別アラートルールを定義する。

元ドキュメント: [可観測性設計.md](../overview/可観測性設計.md)

---

## D-107: 監視・アラート設計

### メトリクス設計（RED / USE メソッド）

サービスの健全性を RED メソッド、インフラリソースを USE メソッドで監視する。

#### RED メソッド（サービスメトリクス）

| メトリクス       | Prometheus メトリクス名                      | 説明                     |
| ---------------- | -------------------------------------------- | ------------------------ |
| Rate（リクエスト率） | `http_requests_total`                    | リクエスト数/秒          |
| Errors（エラー率）   | `http_requests_total{status=~"5.."}`     | 5xx エラー率             |
| Duration（レイテンシ）| `http_request_duration_seconds`          | リクエスト処理時間       |

#### USE メソッド（インフラメトリクス）

| メトリクス           | 対象                  | Prometheus メトリクス名                |
| -------------------- | --------------------- | -------------------------------------- |
| Utilization（使用率）| CPU                   | `container_cpu_usage_seconds_total`    |
| Saturation（飽和度） | Memory                | `container_memory_working_set_bytes`   |
| Errors（エラー）     | Disk I/O              | `node_disk_io_time_seconds_total`      |

#### カスタムメトリクス

サービスは以下のカスタムメトリクスを `/metrics` エンドポイントで公開する。

```yaml
# Go (prometheus/client_golang)
- name: grpc_server_handled_total
  type: counter
  labels: [grpc_service, grpc_method, grpc_code]
  help: Total number of RPCs completed on the server

- name: grpc_server_handling_seconds
  type: histogram
  labels: [grpc_service, grpc_method]
  buckets: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
  help: Histogram of response latency of gRPC

- name: db_query_duration_seconds
  type: histogram
  labels: [query_name, table]
  help: Database query execution time

- name: kafka_messages_produced_total
  type: counter
  labels: [topic]
  help: Total number of Kafka messages produced

- name: kafka_messages_consumed_total
  type: counter
  labels: [topic, consumer_group]
  help: Total number of Kafka messages consumed
```

### Prometheus 構成

> **mTLS 例外**: `observability` Namespace は Istio の **PERMISSIVE** モードで運用する。Prometheus の ServiceMonitor が各サービスの `/metrics` エンドポイントをスクレイプする際、mTLS なしの平文 HTTP を使用するためである。STRICT モードでは Prometheus の scrape が失敗する。この設定は [認証認可設計.md](../../auth/design/認証認可設計.md) および [サービスメッシュ設計.md](../../infrastructure/service-mesh/サービスメッシュ設計.md) と整合している。

```yaml
# Prometheus ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: k1s0-services
  namespace: observability
spec:
  namespaceSelector:
    matchNames:
      - k1s0-system
      - k1s0-business
      - k1s0-service
  selector:
    matchLabels:
      app.kubernetes.io/part-of: k1s0
  endpoints:
    - port: http
      path: /metrics
      interval: 15s
```

### Grafana ダッシュボード構成

| ダッシュボード        | 内容                                         | 対象                |
| --------------------- | -------------------------------------------- | ------------------- |
| Overview              | 全サービスの RED メトリクス一覧               | 全 Tier             |
| Service Detail        | 個別サービスの詳細メトリクス                 | サービス単位        |
| Infrastructure        | ノード・Pod の USE メトリクス                | Kubernetes クラスタ |
| Kafka                 | トピック別のスループット・ラグ               | messaging NS        |
| Kong                  | API Gateway のリクエスト統計                 | k1s0-system NS      |
| Istio                 | サービスメッシュのトラフィック               | service-mesh NS     |
| Database              | PostgreSQL のクエリ統計・接続数              | 各 DB               |
| SLO                   | SLI/SLO のバーンレートとエラーバジェット     | 全サービス          |

### Grafana ダッシュボード パネル定義

#### サービス概要ダッシュボード（Overview）

| パネル名              | PromQL                                                                                              | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| リクエスト数          | `rate(http_requests_total[5m])`                                                                     | Time Series   |
| エラーレート          | `rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])`                      | Time Series   |
| P50 レイテンシ        | `histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))`                           | Time Series   |
| P95 レイテンシ        | `histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))`                           | Time Series   |
| P99 レイテンシ        | `histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))`                           | Time Series   |
| Pod CPU 使用率        | `rate(container_cpu_usage_seconds_total{namespace=~"k1s0-.*"}[5m])`                                 | Gauge         |
| Pod メモリ使用率      | `container_memory_working_set_bytes{namespace=~"k1s0-.*"} / container_spec_memory_limit_bytes`      | Gauge         |

#### Kafka ダッシュボード

| パネル名              | PromQL / メトリクス                                                                                 | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| Consumer Lag          | `kafka_consumer_group_lag`                                                                          | Time Series   |
| メッセージ処理レート  | `rate(kafka_messages_consumed_total[5m])`                                                           | Time Series   |
| メッセージ生成レート  | `rate(kafka_messages_produced_total[5m])`                                                           | Time Series   |
| パーティション数      | `kafka_topic_partitions`                                                                            | Stat          |
| DLQ メッセージ数      | `kafka_consumer_group_lag{topic=~".*\\.dlq"}`                                                       | Stat          |

#### SLO ダッシュボード

| パネル名              | PromQL                                                                                              | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| 可用性                | `sum(rate(http_requests_total{status!~"5.."}[30d])) / sum(rate(http_requests_total[30d]))`           | Gauge         |
| エラーバジェット残量  | `slo:error_budget:remaining`                                                                        | Gauge         |
| バーンレート          | `1 - (sum(rate(http_requests_total{status!~"5.."}[1h])) / sum(rate(http_requests_total[1h])))`      | Time Series   |

### Alertmanager → Teams 通知

アラート通知は Alertmanager から **Microsoft Teams Webhook** へ送信する。

```yaml
# alertmanager.yaml
global:
  resolve_timeout: 5m

route:
  group_by: ['alertname', 'namespace', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: teams-default
  routes:
    - match:
        severity: critical
      receiver: teams-critical
      repeat_interval: 1h
    - match:
        severity: warning
      receiver: teams-warning
      repeat_interval: 4h

receivers:
  - name: teams-default
    webhook_configs:
      - url: 'http://prometheus-msteams:2000/default'
        send_resolved: true

  - name: teams-critical
    webhook_configs:
      - url: 'http://prometheus-msteams:2000/critical'
        send_resolved: true

  - name: teams-warning
    webhook_configs:
      - url: 'http://prometheus-msteams:2000/warning'
        send_resolved: true
```

#### prometheus-msteams 設定

Webhook URL は Kubernetes Secret `prometheus-msteams-webhook` で管理し、環境変数経由で参照する。

```yaml
# Kubernetes Secret（Webhook URL の管理）
# デプロイ時に実際の Webhook URL に置換すること
apiVersion: v1
kind: Secret
metadata:
  name: prometheus-msteams-webhook
  namespace: observability
type: Opaque
stringData:
  default_webhook_url: "https://outlook.office.com/webhook/<REPLACE_WITH_ACTUAL_URL>"    # プレースホルダー: デプロイ時に置換
  critical_webhook_url: "https://outlook.office.com/webhook/<REPLACE_WITH_ACTUAL_URL>"   # プレースホルダー: デプロイ時に置換
  warning_webhook_url: "https://outlook.office.com/webhook/<REPLACE_WITH_ACTUAL_URL>"    # プレースホルダー: デプロイ時に置換
```

```yaml
# prometheus-msteams Deployment（環境変数から Webhook URL を参照）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-msteams
  namespace: observability
spec:
  template:
    spec:
      containers:
        - name: prometheus-msteams
          env:
            - name: TEAMS_DEFAULT_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: prometheus-msteams-webhook
                  key: default_webhook_url
            - name: TEAMS_CRITICAL_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: prometheus-msteams-webhook
                  key: critical_webhook_url
            - name: TEAMS_WARNING_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: prometheus-msteams-webhook
                  key: warning_webhook_url
```

```yaml
# prometheus-msteams ConfigMap（Webhook URL は環境変数から参照）
connectors:
  - default: $(TEAMS_DEFAULT_WEBHOOK_URL)
  - critical: $(TEAMS_CRITICAL_WEBHOOK_URL)
  - warning: $(TEAMS_WARNING_WEBHOOK_URL)
```

### Tier 別アラートルール

> **SLO 目標値とアラート閾値の関係について**
>
> SLO（例: system エラーレート < 0.05%）は **30 日間の累積目標値** であり、瞬間的な逸脱を許容する。
> 一方、アラート閾値は **即座にオペレーター対応が必要な水準** を示す。
> 両者の間には意図的なギャップがあり、多段アラートで段階的にエスカレーションする設計としている。
>
> | Tier | SLO 目標 | warning 閾値（SLO の約 2 倍） | critical 閾値 |
> | --- | --- | --- | --- |
> | system | < 0.05% | > 0.1%（5 分間） | > 1%（5 分間） |
> | business / service | < 0.1% | > 0.2%（5 分間） | > 5%（5 分間） |

#### system Tier

```yaml
groups:
  - name: system-tier-alerts
    rules:
      - alert: SystemServiceErrorRateWarning
        expr: |
          sum(rate(http_requests_total{namespace="k1s0-system", status=~"5.."}[5m]))
          / sum(rate(http_requests_total{namespace="k1s0-system"}[5m])) > 0.001
        for: 5m
        labels:
          severity: warning
          tier: system
        annotations:
          summary: "System Tier error rate > 0.1% (SLO target: < 0.05%)"
          description: "{{ $labels.service }} の 5xx エラー率が {{ $value | humanizePercentage }} です（SLO 目標の約 2 倍）"

      - alert: SystemServiceHighErrorRate
        expr: |
          sum(rate(http_requests_total{namespace="k1s0-system", status=~"5.."}[5m]))
          / sum(rate(http_requests_total{namespace="k1s0-system"}[5m])) > 0.01
        for: 5m
        labels:
          severity: critical
          tier: system
        annotations:
          summary: "System Tier error rate > 1%"
          description: "{{ $labels.service }} の 5xx エラー率が {{ $value | humanizePercentage }} です"

      - alert: SystemServiceHighLatency
        expr: |
          histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{namespace="k1s0-system"}[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
          tier: system
        annotations:
          summary: "System Tier P99 latency > 500ms"
```

#### business / service Tier

```yaml
groups:
  - name: business-service-tier-alerts
    rules:
      - alert: ServiceErrorRateWarning
        expr: |
          sum(rate(http_requests_total{namespace=~"k1s0-business|k1s0-service", status=~"5.."}[5m])) by (service)
          / sum(rate(http_requests_total{namespace=~"k1s0-business|k1s0-service"}[5m])) by (service) > 0.002
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.service }} error rate > 0.2% (SLO target: < 0.1%)"
          description: "{{ $labels.service }} の 5xx エラー率が {{ $value | humanizePercentage }} です（SLO 目標の約 2 倍）"

      - alert: ServiceHighErrorRate
        expr: |
          sum(rate(http_requests_total{namespace=~"k1s0-business|k1s0-service", status=~"5.."}[5m])) by (service)
          / sum(rate(http_requests_total{namespace=~"k1s0-business|k1s0-service"}[5m])) by (service) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "{{ $labels.service }} error rate > 5%"

      - alert: ServiceHighLatency
        expr: |
          histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{namespace=~"k1s0-business|k1s0-service"}[5m])) by (service) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.service }} P99 latency > 1s"
```

#### 環境別アラート抑制

| 環境    | critical 通知 | warning 通知 | 備考                       |
| ------- | ------------- | ------------ | -------------------------- |
| dev     | 無効          | 無効         | 開発者がローカルで確認     |
| staging | 有効          | 無効         | 重大な問題のみ通知         |
| prod    | 有効          | 有効         | 全アラートを通知           |

```yaml
# staging 環境での warning 抑制
route:
  routes:
    - match:
        severity: warning
        environment: staging
      receiver: 'null'    # 通知しない
```

---

## 関連ドキュメント

- [可観測性設計.md](../overview/可観測性設計.md) -- 基本方針・概要
- [可観測性-SLO設計.md](../slo/SLO設計.md) -- SLO/SLA・エラーバジェット
- [可観測性-トレーシング設計.md](../tracing/トレーシング設計.md) -- 分散トレーシング
- [可観測性-ログ設計.md](../logging/ログ設計.md) -- 構造化ログ・Loki
- [認証認可設計.md](../../auth/design/認証認可設計.md) -- 認証・認可設計
- [サービスメッシュ設計.md](../../infrastructure/service-mesh/サービスメッシュ設計.md) -- Istio 設計
