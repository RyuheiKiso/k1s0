# 可観測性設計

k1s0 における監視・アラート・SLO/SLA・構造化ログの設計を定義する。
Tier アーキテクチャの詳細は [tier-architecture.md](tier-architecture.md) を参照。

## 基本方針

- **メトリクス**: Prometheus で収集し、Grafana で可視化する
- **ログ**: JSON 構造化ログを標準とし、Loki で集約する
- **トレース**: OpenTelemetry + Jaeger で分散トレーシングを実現する
- **アラート**: Alertmanager から Microsoft Teams へ通知する
- すべてのコンポーネントは `observability` Namespace にデプロイする

---

## D-107: 監視・アラート設計

### メトリクス設計（RED / USE メソッド）

サービスの健全性を RED メソッド、インフラリソースを USE メソッドで監視する。

#### RED メソッド（サービスメトリクス）

| メトリクス       | Prometheus メトリクス名                      | 説明                     |
| ---------------- | -------------------------------------------- | ------------------------ |
| Rate（リクエスト率） | `http_requests_total`                    | リクエスト数/秒          |
| Errors（エラー率）   | `http_requests_total{status=~"5.."}`     | 5xx エラー率             |
| Duration（レイテンシ）| `http_request_duration_seconds`          | リクエスト処理時間       |

#### USE メソッド（インフラメトリクス）

| メトリクス           | 対象                  | Prometheus メトリクス名                |
| -------------------- | --------------------- | -------------------------------------- |
| Utilization（使用率）| CPU                   | `container_cpu_usage_seconds_total`    |
| Saturation（飽和度） | Memory                | `container_memory_working_set_bytes`   |
| Errors（エラー）     | Disk I/O              | `node_disk_io_time_seconds_total`      |

#### カスタムメトリクス

サービスは以下のカスタムメトリクスを `/metrics` エンドポイントで公開する。

```yaml
# Go (prometheus/client_golang)
- name: grpc_server_handled_total
  type: counter
  labels: [grpc_service, grpc_method, grpc_code]
  help: Total number of RPCs completed on the server

- name: grpc_server_handling_seconds
  type: histogram
  labels: [grpc_service, grpc_method]
  buckets: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
  help: Histogram of response latency of gRPC

- name: db_query_duration_seconds
  type: histogram
  labels: [query_name, table]
  help: Database query execution time

- name: kafka_messages_produced_total
  type: counter
  labels: [topic]
  help: Total number of Kafka messages produced

- name: kafka_messages_consumed_total
  type: counter
  labels: [topic, consumer_group]
  help: Total number of Kafka messages consumed
```

### Prometheus 構成

```yaml
# Prometheus ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: k1s0-services
  namespace: observability
spec:
  namespaceSelector:
    matchNames:
      - k1s0-system
      - k1s0-business
      - k1s0-service
  selector:
    matchLabels:
      app.kubernetes.io/part-of: k1s0
  endpoints:
    - port: http
      path: /metrics
      interval: 15s
```

### Grafana ダッシュボード構成

| ダッシュボード        | 内容                                         | 対象                |
| --------------------- | -------------------------------------------- | ------------------- |
| Overview              | 全サービスの RED メトリクス一覧               | 全 Tier             |
| Service Detail        | 個別サービスの詳細メトリクス                 | サービス単位        |
| Infrastructure        | ノード・Pod の USE メトリクス                | Kubernetes クラスタ |
| Kafka                 | トピック別のスループット・ラグ               | messaging NS        |
| Kong                  | API Gateway のリクエスト統計                 | ingress NS          |
| Istio                 | サービスメッシュのトラフィック               | service-mesh NS     |
| Database              | PostgreSQL のクエリ統計・接続数              | 各 DB               |
| SLO                   | SLI/SLO のバーンレートとエラーバジェット     | 全サービス          |

### Alertmanager → Teams 通知

アラート通知は Alertmanager から **Microsoft Teams Webhook** へ送信する。

```yaml
# alertmanager.yaml
global:
  resolve_timeout: 5m

route:
  group_by: ['alertname', 'namespace', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: teams-default
  routes:
    - match:
        severity: critical
      receiver: teams-critical
      repeat_interval: 1h
    - match:
        severity: warning
      receiver: teams-warning
      repeat_interval: 4h

receivers:
  - name: teams-default
    webhook_configs:
      - url: 'http://prometheus-msteams:2000/default'
        send_resolved: true

  - name: teams-critical
    webhook_configs:
      - url: 'http://prometheus-msteams:2000/critical'
        send_resolved: true

  - name: teams-warning
    webhook_configs:
      - url: 'http://prometheus-msteams:2000/warning'
        send_resolved: true
```

#### prometheus-msteams 設定

```yaml
# prometheus-msteams ConfigMap
connectors:
  - default: "https://outlook.office.com/webhook/xxx/IncomingWebhook/yyy"
  - critical: "https://outlook.office.com/webhook/xxx/IncomingWebhook/zzz-critical"
  - warning: "https://outlook.office.com/webhook/xxx/IncomingWebhook/zzz-warning"
```

### Tier 別アラートルール

#### system Tier

```yaml
groups:
  - name: system-tier-alerts
    rules:
      - alert: SystemServiceHighErrorRate
        expr: |
          sum(rate(http_requests_total{namespace="k1s0-system", status=~"5.."}[5m]))
          / sum(rate(http_requests_total{namespace="k1s0-system"}[5m])) > 0.01
        for: 5m
        labels:
          severity: critical
          tier: system
        annotations:
          summary: "System Tier error rate > 1%"
          description: "{{ $labels.service }} の 5xx エラー率が {{ $value | humanizePercentage }} です"

      - alert: SystemServiceHighLatency
        expr: |
          histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{namespace="k1s0-system"}[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
          tier: system
        annotations:
          summary: "System Tier P99 latency > 500ms"
```

#### business / service Tier

```yaml
groups:
  - name: business-service-tier-alerts
    rules:
      - alert: ServiceHighErrorRate
        expr: |
          sum(rate(http_requests_total{namespace=~"k1s0-business|k1s0-service", status=~"5.."}[5m])) by (service)
          / sum(rate(http_requests_total{namespace=~"k1s0-business|k1s0-service"}[5m])) by (service) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "{{ $labels.service }} error rate > 5%"

      - alert: ServiceHighLatency
        expr: |
          histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{namespace=~"k1s0-business|k1s0-service"}[5m])) by (service) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.service }} P99 latency > 1s"
```

#### 環境別アラート抑制

| 環境    | critical 通知 | warning 通知 | 備考                       |
| ------- | ------------- | ------------ | -------------------------- |
| dev     | 無効          | 無効         | 開発者がローカルで確認     |
| staging | 有効          | 無効         | 重大な問題のみ通知         |
| prod    | 有効          | 有効         | 全アラートを通知           |

```yaml
# staging 環境での warning 抑制
route:
  routes:
    - match:
        severity: warning
        environment: staging
      receiver: 'null'    # 通知しない
```

---

## D-108: SLO/SLA 定義

### SLI（Service Level Indicators）

| SLI          | 定義                                                    | 計測方法                                    |
| ------------ | ------------------------------------------------------- | ------------------------------------------- |
| 可用性       | 正常レスポンス数 / 全リクエスト数                       | `http_requests_total{status!~"5.."} / total` |
| レイテンシ   | P99 レスポンスタイム                                    | `histogram_quantile(0.99, ...)`             |
| エラーレート | 5xx レスポンス率                                        | `rate(http_requests_total{status=~"5.."})`  |

### SLO（Service Level Objectives）

#### system Tier

| SLO               | 目標値   | 計測期間 | エラーバジェット（30日） |
| ------------------ | -------- | -------- | ------------------------ |
| 可用性             | 99.95%   | 30 日    | 21.6 分                  |
| P99 レイテンシ     | < 200ms  | 30 日    | -                        |
| エラーレート       | < 0.05%  | 30 日    | -                        |

#### business Tier

| SLO               | 目標値   | 計測期間 | エラーバジェット（30日） |
| ------------------ | -------- | -------- | ------------------------ |
| 可用性             | 99.9%    | 30 日    | 43.2 分                  |
| P99 レイテンシ     | < 500ms  | 30 日    | -                        |
| エラーレート       | < 0.1%   | 30 日    | -                        |

#### service Tier

| SLO               | 目標値   | 計測期間 | エラーバジェット（30日） |
| ------------------ | -------- | -------- | ------------------------ |
| 可用性             | 99.9%    | 30 日    | 43.2 分                  |
| P99 レイテンシ     | < 1s     | 30 日    | -                        |
| エラーレート       | < 0.1%   | 30 日    | -                        |

### エラーバジェット運用

```
エラーバジェット = 1 - SLO目標値
エラーバジェット残量 = エラーバジェット - 実測エラー率
```

| バジェット残量 | アクション                                      |
| -------------- | ----------------------------------------------- |
| > 50%          | 通常運用。新機能リリース可能                    |
| 25% - 50%      | 注意。リリース頻度を下げ、信頼性改善に注力      |
| < 25%          | 警告。新機能リリースを凍結し、信頼性改善に専念  |
| 0%             | リリース凍結。ポストモーテム実施                |

#### Prometheus Recording Rule

```yaml
groups:
  - name: slo-recording-rules
    rules:
      - record: slo:availability:ratio
        expr: |
          sum(rate(http_requests_total{status!~"5.."}[30d])) by (namespace, service)
          / sum(rate(http_requests_total[30d])) by (namespace, service)

      - record: slo:error_budget:remaining
        expr: |
          1 - (
            (1 - slo:availability:ratio)
            / (1 - 0.999)
          )
```

---

## D-109: 構造化ログ設計

### JSON ログ標準フィールド

すべてのサービスは JSON 形式の構造化ログを標準出力に出力する。

```json
{
  "timestamp": "2026-02-15T10:30:00.123Z",
  "level": "info",
  "message": "Request completed",
  "service": "order-server",
  "version": "1.2.3",
  "tier": "service",
  "environment": "prod",
  "trace_id": "abc123def456",
  "span_id": "789ghi012",
  "request_id": "req_xyz789",
  "method": "POST",
  "path": "/api/v1/orders",
  "status": 201,
  "duration_ms": 45,
  "user_id": "usr_123",
  "error": null
}
```

### 標準フィールド定義

| フィールド    | 型     | 必須 | 説明                              |
| ------------- | ------ | ---- | --------------------------------- |
| `timestamp`   | string | Yes  | ISO 8601 形式（UTC）              |
| `level`       | string | Yes  | `debug`, `info`, `warn`, `error`  |
| `message`     | string | Yes  | ログメッセージ                    |
| `service`     | string | Yes  | サービス名                        |
| `version`     | string | Yes  | アプリケーションバージョン        |
| `tier`        | string | Yes  | `system`, `business`, `service`   |
| `environment` | string | Yes  | `dev`, `staging`, `prod`          |
| `trace_id`    | string | No   | 分散トレースの Trace ID           |
| `span_id`     | string | No   | 分散トレースの Span ID            |
| `request_id`  | string | No   | リクエスト追跡 ID                 |
| `error`       | object | No   | エラー詳細（スタックトレース等）  |

### トレース相関

OpenTelemetry で伝搬される `trace_id` と `span_id` をログに埋め込み、ログとトレースを相関させる。

```
Client → Kong → Service A → Service B
  │                │              │
  └── trace_id: abc123 ──────────┘
       span_id: A001   span_id: B001
```

Grafana でログとトレースを統合表示し、trace_id をキーにドリルダウン可能にする。

### 環境別ログレベル

| 環境    | デフォルトレベル | 出力先   |
| ------- | ---------------- | -------- |
| dev     | debug            | stdout   |
| staging | info             | stdout   |
| prod    | warn             | stdout   |

### Go 実装例（slog）

```go
// internal/infra/config/logger.go
package config

import (
    "log/slog"
    "os"

    "go.opentelemetry.io/otel/trace"
)

func NewLogger(env, service, version, tier string) *slog.Logger {
    level := slog.LevelWarn
    switch env {
    case "dev":
        level = slog.LevelDebug
    case "staging":
        level = slog.LevelInfo
    }

    handler := slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{
        Level: level,
    })

    return slog.New(handler).With(
        slog.String("service", service),
        slog.String("version", version),
        slog.String("tier", tier),
        slog.String("environment", env),
    )
}

// トレースコンテキストをログに埋め込むミドルウェア
func LogWithTrace(ctx context.Context, logger *slog.Logger) *slog.Logger {
    spanCtx := trace.SpanContextFromContext(ctx)
    if spanCtx.HasTraceID() {
        return logger.With(
            slog.String("trace_id", spanCtx.TraceID().String()),
            slog.String("span_id", spanCtx.SpanID().String()),
        )
    }
    return logger
}
```

### Rust 実装例（tracing）

```rust
// src/infra/config/logger.rs
use tracing_subscriber::{fmt, EnvFilter, layer::SubscriberExt, util::SubscriberInitExt};

pub fn init_logger(env: &str) {
    let filter = match env {
        "dev" => "debug",
        "staging" => "info",
        _ => "warn",
    };

    tracing_subscriber::registry()
        .with(EnvFilter::new(filter))
        .with(
            fmt::layer()
                .json()
                .with_target(true)
                .with_span_events(fmt::format::FmtSpan::CLOSE),
        )
        .init();
}

// リクエストハンドラーでのトレース付きログ
#[tracing::instrument(
    skip(state),
    fields(
        service = "order-server",
        tier = "service",
    )
)]
async fn create_order(
    State(state): State<AppState>,
    Json(input): Json<CreateOrderInput>,
) -> Result<Json<Order>, AppError> {
    tracing::info!(
        method = "POST",
        path = "/api/v1/orders",
        "Processing create order request"
    );
    // ...
}
```

### ログ集約（Loki）

```yaml
# Loki Stack (Promtail → Loki → Grafana)
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: observability
data:
  promtail.yaml: |
    server:
      http_listen_port: 3101
    positions:
      filename: /tmp/positions.yaml
    clients:
      - url: http://loki:3100/loki/api/v1/push
    scrape_configs:
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
            target_label: app
          - source_labels: [__meta_kubernetes_pod_label_tier]
            target_label: tier
        pipeline_stages:
          - json:
              expressions:
                level: level
                trace_id: trace_id
                service: service
          - labels:
              level:
              trace_id:
              service:
```

---

## 関連ドキュメント

- [tier-architecture.md](tier-architecture.md) — Tier アーキテクチャの詳細
- [kubernetes設計.md](kubernetes設計.md) — Namespace・NetworkPolicy 設計
- [インフラ設計.md](インフラ設計.md) — オンプレミスインフラ構成
- [サービスメッシュ設計.md](サービスメッシュ設計.md) — Istio 設計・耐障害性
- [config設計.md](config設計.md) — config.yaml スキーマと環境別管理
- [CI-CD設計.md](CI-CD設計.md) — CI/CD パイプライン設計
