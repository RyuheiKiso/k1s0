# 可観測性設計

k1s0 における監視・アラート・SLO/SLA・構造化ログの設計を定義する。
Tier アーキテクチャの詳細は [tier-architecture.md](tier-architecture.md) を参照。

## 基本方針

- **メトリクス**: Prometheus で収集し、Grafana で可視化する
- **ログ**: JSON 構造化ログを標準とし、Loki で集約する
- **トレース**: OpenTelemetry + Jaeger で分散トレーシングを実現する
- **アラート**: Alertmanager から Microsoft Teams へ通知する
- すべてのコンポーネントは `observability` Namespace にデプロイする

---

## D-107: 監視・アラート設計

### メトリクス設計（RED / USE メソッド）

サービスの健全性を RED メソッド、インフラリソースを USE メソッドで監視する。

#### RED メソッド（サービスメトリクス）

| メトリクス       | Prometheus メトリクス名                      | 説明                     |
| ---------------- | -------------------------------------------- | ------------------------ |
| Rate（リクエスト率） | `http_requests_total`                    | リクエスト数/秒          |
| Errors（エラー率）   | `http_requests_total{status=~"5.."}`     | 5xx エラー率             |
| Duration（レイテンシ）| `http_request_duration_seconds`          | リクエスト処理時間       |

#### USE メソッド（インフラメトリクス）

| メトリクス           | 対象                  | Prometheus メトリクス名                |
| -------------------- | --------------------- | -------------------------------------- |
| Utilization（使用率）| CPU                   | `container_cpu_usage_seconds_total`    |
| Saturation（飽和度） | Memory                | `container_memory_working_set_bytes`   |
| Errors（エラー）     | Disk I/O              | `node_disk_io_time_seconds_total`      |

#### カスタムメトリクス

サービスは以下のカスタムメトリクスを `/metrics` エンドポイントで公開する。

```yaml
# Go (prometheus/client_golang)
- name: grpc_server_handled_total
  type: counter
  labels: [grpc_service, grpc_method, grpc_code]
  help: Total number of RPCs completed on the server

- name: grpc_server_handling_seconds
  type: histogram
  labels: [grpc_service, grpc_method]
  buckets: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
  help: Histogram of response latency of gRPC

- name: db_query_duration_seconds
  type: histogram
  labels: [query_name, table]
  help: Database query execution time

- name: kafka_messages_produced_total
  type: counter
  labels: [topic]
  help: Total number of Kafka messages produced

- name: kafka_messages_consumed_total
  type: counter
  labels: [topic, consumer_group]
  help: Total number of Kafka messages consumed
```

### Prometheus 構成

> **mTLS 例外**: `observability` Namespace は Istio の **PERMISSIVE** モードで運用する。Prometheus の ServiceMonitor が各サービスの `/metrics` エンドポイントをスクレイプする際、mTLS なしの平文 HTTP を使用するためである。STRICT モードでは Prometheus の scrape が失敗する。この設定は [認証認可設計.md](認証認可設計.md) および [サービスメッシュ設計.md](サービスメッシュ設計.md) と整合している。

```yaml
# Prometheus ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: k1s0-services
  namespace: observability
spec:
  namespaceSelector:
    matchNames:
      - k1s0-system
      - k1s0-business
      - k1s0-service
  selector:
    matchLabels:
      app.kubernetes.io/part-of: k1s0
  endpoints:
    - port: http
      path: /metrics
      interval: 15s
```

### Grafana ダッシュボード構成

| ダッシュボード        | 内容                                         | 対象                |
| --------------------- | -------------------------------------------- | ------------------- |
| Overview              | 全サービスの RED メトリクス一覧               | 全 Tier             |
| Service Detail        | 個別サービスの詳細メトリクス                 | サービス単位        |
| Infrastructure        | ノード・Pod の USE メトリクス                | Kubernetes クラスタ |
| Kafka                 | トピック別のスループット・ラグ               | messaging NS        |
| Kong                  | API Gateway のリクエスト統計                 | k1s0-system NS      |
| Istio                 | サービスメッシュのトラフィック               | service-mesh NS     |
| Database              | PostgreSQL のクエリ統計・接続数              | 各 DB               |
| SLO                   | SLI/SLO のバーンレートとエラーバジェット     | 全サービス          |

### Grafana ダッシュボード パネル定義

#### サービス概要ダッシュボード（Overview）

| パネル名              | PromQL                                                                                              | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| リクエスト数          | `rate(http_requests_total[5m])`                                                                     | Time Series   |
| エラーレート          | `rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])`                      | Time Series   |
| P50 レイテンシ        | `histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))`                           | Time Series   |
| P95 レイテンシ        | `histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))`                           | Time Series   |
| P99 レイテンシ        | `histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))`                           | Time Series   |
| Pod CPU 使用率        | `rate(container_cpu_usage_seconds_total{namespace=~"k1s0-.*"}[5m])`                                 | Gauge         |
| Pod メモリ使用率      | `container_memory_working_set_bytes{namespace=~"k1s0-.*"} / container_spec_memory_limit_bytes`      | Gauge         |

#### Kafka ダッシュボード

| パネル名              | PromQL / メトリクス                                                                                 | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| Consumer Lag          | `kafka_consumer_group_lag`                                                                          | Time Series   |
| メッセージ処理レート  | `rate(kafka_messages_consumed_total[5m])`                                                           | Time Series   |
| メッセージ生成レート  | `rate(kafka_messages_produced_total[5m])`                                                           | Time Series   |
| パーティション数      | `kafka_topic_partitions`                                                                            | Stat          |
| DLQ メッセージ数      | `kafka_consumer_group_lag{topic=~".*\\.dlq"}`                                                       | Stat          |

#### SLO ダッシュボード

| パネル名              | PromQL                                                                                              | 可視化タイプ  |
| --------------------- | --------------------------------------------------------------------------------------------------- | ------------- |
| 可用性                | `sum(rate(http_requests_total{status!~"5.."}[30d])) / sum(rate(http_requests_total[30d]))`           | Gauge         |
| エラーバジェット残量  | `slo:error_budget:remaining`                                                                        | Gauge         |
| バーンレート          | `1 - (sum(rate(http_requests_total{status!~"5.."}[1h])) / sum(rate(http_requests_total[1h])))`      | Time Series   |

### Alertmanager → Teams 通知

アラート通知は Alertmanager から **Microsoft Teams Webhook** へ送信する。

```yaml
# alertmanager.yaml
global:
  resolve_timeout: 5m

route:
  group_by: ['alertname', 'namespace', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: teams-default
  routes:
    - match:
        severity: critical
      receiver: teams-critical
      repeat_interval: 1h
    - match:
        severity: warning
      receiver: teams-warning
      repeat_interval: 4h

receivers:
  - name: teams-default
    webhook_configs:
      - url: 'http://prometheus-msteams:2000/default'
        send_resolved: true

  - name: teams-critical
    webhook_configs:
      - url: 'http://prometheus-msteams:2000/critical'
        send_resolved: true

  - name: teams-warning
    webhook_configs:
      - url: 'http://prometheus-msteams:2000/warning'
        send_resolved: true
```

#### prometheus-msteams 設定

Webhook URL は Kubernetes Secret `prometheus-msteams-webhook` で管理し、環境変数経由で参照する。

```yaml
# Kubernetes Secret（Webhook URL の管理）
# デプロイ時に実際の Webhook URL に置換すること
apiVersion: v1
kind: Secret
metadata:
  name: prometheus-msteams-webhook
  namespace: observability
type: Opaque
stringData:
  default_webhook_url: "https://outlook.office.com/webhook/<REPLACE_WITH_ACTUAL_URL>"    # プレースホルダー: デプロイ時に置換
  critical_webhook_url: "https://outlook.office.com/webhook/<REPLACE_WITH_ACTUAL_URL>"   # プレースホルダー: デプロイ時に置換
  warning_webhook_url: "https://outlook.office.com/webhook/<REPLACE_WITH_ACTUAL_URL>"    # プレースホルダー: デプロイ時に置換
```

```yaml
# prometheus-msteams Deployment（環境変数から Webhook URL を参照）
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-msteams
  namespace: observability
spec:
  template:
    spec:
      containers:
        - name: prometheus-msteams
          env:
            - name: TEAMS_DEFAULT_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: prometheus-msteams-webhook
                  key: default_webhook_url
            - name: TEAMS_CRITICAL_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: prometheus-msteams-webhook
                  key: critical_webhook_url
            - name: TEAMS_WARNING_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: prometheus-msteams-webhook
                  key: warning_webhook_url
```

```yaml
# prometheus-msteams ConfigMap（Webhook URL は環境変数から参照）
connectors:
  - default: $(TEAMS_DEFAULT_WEBHOOK_URL)
  - critical: $(TEAMS_CRITICAL_WEBHOOK_URL)
  - warning: $(TEAMS_WARNING_WEBHOOK_URL)
```

### Tier 別アラートルール

> **SLO 目標値とアラート閾値の関係について**
>
> SLO（例: system エラーレート < 0.05%）は **30 日間の累積目標値** であり、瞬間的な逸脱を許容する。
> 一方、アラート閾値は **即座にオペレーター対応が必要な水準** を示す。
> 両者の間には意図的なギャップがあり、多段アラートで段階的にエスカレーションする設計としている。
>
> | Tier | SLO 目標 | warning 閾値（SLO の約 2 倍） | critical 閾値 |
> | --- | --- | --- | --- |
> | system | < 0.05% | > 0.1%（5 分間） | > 1%（5 分間） |
> | business / service | < 0.1% | > 0.2%（5 分間） | > 5%（5 分間） |

#### system Tier

```yaml
groups:
  - name: system-tier-alerts
    rules:
      - alert: SystemServiceErrorRateWarning
        expr: |
          sum(rate(http_requests_total{namespace="k1s0-system", status=~"5.."}[5m]))
          / sum(rate(http_requests_total{namespace="k1s0-system"}[5m])) > 0.001
        for: 5m
        labels:
          severity: warning
          tier: system
        annotations:
          summary: "System Tier error rate > 0.1% (SLO target: < 0.05%)"
          description: "{{ $labels.service }} の 5xx エラー率が {{ $value | humanizePercentage }} です（SLO 目標の約 2 倍）"

      - alert: SystemServiceHighErrorRate
        expr: |
          sum(rate(http_requests_total{namespace="k1s0-system", status=~"5.."}[5m]))
          / sum(rate(http_requests_total{namespace="k1s0-system"}[5m])) > 0.01
        for: 5m
        labels:
          severity: critical
          tier: system
        annotations:
          summary: "System Tier error rate > 1%"
          description: "{{ $labels.service }} の 5xx エラー率が {{ $value | humanizePercentage }} です"

      - alert: SystemServiceHighLatency
        expr: |
          histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{namespace="k1s0-system"}[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
          tier: system
        annotations:
          summary: "System Tier P99 latency > 500ms"
```

#### business / service Tier

```yaml
groups:
  - name: business-service-tier-alerts
    rules:
      - alert: ServiceErrorRateWarning
        expr: |
          sum(rate(http_requests_total{namespace=~"k1s0-business|k1s0-service", status=~"5.."}[5m])) by (service)
          / sum(rate(http_requests_total{namespace=~"k1s0-business|k1s0-service"}[5m])) by (service) > 0.002
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.service }} error rate > 0.2% (SLO target: < 0.1%)"
          description: "{{ $labels.service }} の 5xx エラー率が {{ $value | humanizePercentage }} です（SLO 目標の約 2 倍）"

      - alert: ServiceHighErrorRate
        expr: |
          sum(rate(http_requests_total{namespace=~"k1s0-business|k1s0-service", status=~"5.."}[5m])) by (service)
          / sum(rate(http_requests_total{namespace=~"k1s0-business|k1s0-service"}[5m])) by (service) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "{{ $labels.service }} error rate > 5%"

      - alert: ServiceHighLatency
        expr: |
          histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{namespace=~"k1s0-business|k1s0-service"}[5m])) by (service) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.service }} P99 latency > 1s"
```

#### 環境別アラート抑制

| 環境    | critical 通知 | warning 通知 | 備考                       |
| ------- | ------------- | ------------ | -------------------------- |
| dev     | 無効          | 無効         | 開発者がローカルで確認     |
| staging | 有効          | 無効         | 重大な問題のみ通知         |
| prod    | 有効          | 有効         | 全アラートを通知           |

```yaml
# staging 環境での warning 抑制
route:
  routes:
    - match:
        severity: warning
        environment: staging
      receiver: 'null'    # 通知しない
```

---

## D-108: SLO/SLA 定義

### SLI（Service Level Indicators）

| SLI          | 定義                                                    | 計測方法                                    |
| ------------ | ------------------------------------------------------- | ------------------------------------------- |
| 可用性       | 正常レスポンス数 / 全リクエスト数                       | `http_requests_total{status!~"5.."} / total` |
| レイテンシ   | P99 レスポンスタイム                                    | `histogram_quantile(0.99, ...)`             |
| エラーレート | 5xx レスポンス率                                        | `rate(http_requests_total{status=~"5.."})`  |

### SLO（Service Level Objectives）

> **可用性とエラーレートの関係**: 可用性 SLO は「正常レスポンス数 / 全リクエスト数」で計測するため、可用性 99.95% はエラーレート < 0.05% と同義である。同様に、可用性 99.9% はエラーレート < 0.1% と同義である。以下の表では両指標を並記し、計測方法の違いを明示する。

#### system Tier

| SLO               | 目標値   | 計測期間 | エラーバジェット（30日） |
| ------------------ | -------- | -------- | ------------------------ |
| 可用性             | 99.95%   | 30 日    | 21.6 分                  |
| P99 レイテンシ     | < 200ms  | 30 日    | -                        |
| エラーレート       | < 0.05%  | 30 日    | -（可用性 99.95% と同義）|

#### business Tier

| SLO               | 目標値   | 計測期間 | エラーバジェット（30日） |
| ------------------ | -------- | -------- | ------------------------ |
| 可用性             | 99.9%    | 30 日    | 43.2 分                  |
| P99 レイテンシ     | < 500ms  | 30 日    | -                        |
| エラーレート       | < 0.1%   | 30 日    | -（可用性 99.9% と同義） |

#### service Tier

| SLO               | 目標値   | 計測期間 | エラーバジェット（30日） |
| ------------------ | -------- | -------- | ------------------------ |
| 可用性             | 99.9%    | 30 日    | 43.2 分                  |
| P99 レイテンシ     | < 1s     | 30 日    | -                        |
| エラーレート       | < 0.1%   | 30 日    | -（可用性 99.9% と同義） |

### SLA（Service Level Agreements）

#### 内部 SLA（チーム間合意）

| Tier     | 可用性    | P99 レイテンシ | 計測期間 |
| -------- | --------- | -------------- | -------- |
| system   | 99.9%     | < 500ms        | 月間     |
| business | 99.8%     | < 1s           | 月間     |
| service  | 99.8%     | < 2s           | 月間     |

#### SLA 違反時のエスカレーション

| 条件                   | アクション                                                     |
| ---------------------- | -------------------------------------------------------------- |
| リアルタイム可用性低下 | 即座にオンコール担当に通知（Alertmanager → Teams 連携）        |
| 月間 SLA 未達          | 月次レビューで原因分析と再発防止策を検討、ポストモーテム実施   |

### エラーバジェット運用

```
エラーバジェット = 1 - SLO目標値
エラーバジェット残量 = エラーバジェット - 実測エラー率
```

| バジェット残量 | アクション                                      |
| -------------- | ----------------------------------------------- |
| > 50%          | 通常運用。新機能リリース可能                    |
| 25% - 50%      | 注意。リリース頻度を下げ、信頼性改善に注力      |
| < 25%          | 警告。新機能リリースを凍結し、信頼性改善に専念  |
| 0%             | リリース凍結。ポストモーテム実施                |

#### Prometheus Recording Rule

```yaml
groups:
  - name: slo-recording-rules
    rules:
      - record: slo:availability:ratio
        expr: |
          sum(rate(http_requests_total{status!~"5.."}[30d])) by (namespace, service)
          / sum(rate(http_requests_total[30d])) by (namespace, service)

      - record: slo:error_budget:remaining
        expr: |
          1 - (
            (1 - slo:availability:ratio)
            / (1 - (
              label_replace(
                vector(0.9995) and on() (kube_namespace_labels{namespace="k1s0-system"})
                or vector(0.999),
                "namespace", "$1", "namespace", "(.*)"
              )
            ))
          )
        # system Tier: 可用性目標 99.95%（0.9995）
        # business / service Tier: 可用性目標 99.9%（0.999）
```

---

## D-110: 分散トレーシング設計（OpenTelemetry）

### OpenTelemetry SDK 初期化パターン

#### Go

```go
package otel

import (
    "context"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
    "go.opentelemetry.io/otel/sdk/resource"
    sdktrace "go.opentelemetry.io/otel/sdk/trace"
    semconv "go.opentelemetry.io/otel/semconv/v1.21.0"
)

func initTracer(ctx context.Context, serviceName string) (*sdktrace.TracerProvider, error) {
    exporter, err := otlptracegrpc.New(ctx)
    if err != nil {
        return nil, err
    }
    tp := sdktrace.NewTracerProvider(
        sdktrace.WithBatcher(exporter),
        sdktrace.WithResource(resource.NewWithAttributes(
            semconv.SchemaURL,
            semconv.ServiceNameKey.String(serviceName),
        )),
    )
    otel.SetTracerProvider(tp)
    return tp, nil
}
```

#### Rust

```rust
use opentelemetry::global;
use opentelemetry_otlp::SpanExporter;
use opentelemetry_sdk::{trace as sdktrace, Resource};
use std::error::Error;

fn init_tracer(service_name: &str) -> Result<sdktrace::TracerProvider, Box<dyn Error>> {
    let exporter = SpanExporter::builder()
        .with_tonic()
        .build()?;
    let provider = sdktrace::TracerProvider::builder()
        .with_batch_exporter(exporter)
        .with_resource(Resource::builder()
            .with_service_name(service_name)
            .build())
        .build();
    global::set_tracer_provider(provider.clone());
    Ok(provider)
}
```

### 自動インストルメンテーション

| 言語 | ライブラリ                | 用途                                           |
| ---- | ------------------------- | ---------------------------------------------- |
| Go   | `otelhttp` ミドルウェア   | HTTP サーバー/クライアントの自動スパン生成      |
| Rust | `tracing-opentelemetry`   | `tracing` クレートとの統合によるスパン自動生成  |

### カスタムスパン ガイドライン

ビジネスロジックの重要な処理にはカスタムスパンを追加し、処理の可視性を高める。

**カスタムスパンを追加すべき箇所:**
- 外部サービス呼び出し（gRPC / HTTP クライアント）
- データベースクエリ（特に複雑なトランザクション）
- Kafka メッセージの Produce / Consume
- Saga の各ステップ実行
- キャッシュの読み書き

**Go でのカスタムスパン例:**

```go
func (s *OrderService) CreateOrder(ctx context.Context, input CreateOrderInput) (*Order, error) {
    ctx, span := otel.Tracer("order-server").Start(ctx, "OrderService.CreateOrder")
    defer span.End()

    span.SetAttributes(
        attribute.String("order.customer_id", input.CustomerID),
        attribute.Int("order.item_count", len(input.Items)),
    )

    // ビジネスロジック...
}
```

**Rust でのカスタムスパン例:**

```rust
#[tracing::instrument(skip(self), fields(order.customer_id = %input.customer_id))]
async fn create_order(&self, input: CreateOrderInput) -> Result<Order, AppError> {
    tracing::info!("Creating order");
    // ビジネスロジック...
}
```

---

## D-109: 構造化ログ設計

### JSON ログ標準フィールド

すべてのサービスは JSON 形式の構造化ログを標準出力に出力する。

```json
{
  "timestamp": "2026-02-15T10:30:00.123Z",
  "level": "info",
  "message": "Request completed",
  "service": "order-server",
  "version": "1.2.3",
  "tier": "service",
  "environment": "prod",
  "trace_id": "abc123def456",
  "span_id": "789ghi012",
  "request_id": "req_xyz789",
  "method": "POST",
  "path": "/api/v1/orders",
  "status": 201,
  "duration_ms": 45,
  "user_id": "usr_123",
  "error": null
}
```

### 標準フィールド定義

| フィールド    | 型     | 必須 | 説明                              |
| ------------- | ------ | ---- | --------------------------------- |
| `timestamp`   | string | Yes  | ISO 8601 形式（UTC）              |
| `level`       | string | Yes  | `debug`, `info`, `warn`, `error`  |
| `message`     | string | Yes  | ログメッセージ                    |
| `service`     | string | Yes  | サービス名                        |
| `version`     | string | Yes  | アプリケーションバージョン        |
| `tier`        | string | Yes  | `system`, `business`, `service`   |
| `environment` | string | Yes  | `dev`, `staging`, `prod`          |
| `trace_id`    | string | No   | 分散トレースの Trace ID           |
| `span_id`     | string | No   | 分散トレースの Span ID            |
| `request_id`  | string | No   | リクエスト追跡 ID                 |
| `error`       | object | No   | エラー詳細（スタックトレース等）  |

### トレース相関

OpenTelemetry で伝搬される `trace_id` と `span_id` をログに埋め込み、ログとトレースを相関させる。

```
Client → Kong → Service A → Service B
  │                │              │
  └── trace_id: abc123 ──────────┘
       span_id: A001   span_id: B001
```

Grafana でログとトレースを統合表示し、trace_id をキーにドリルダウン可能にする。

### 環境別ログレベル

| 環境    | デフォルトレベル | フォーマット | 出力先   |
| ------- | ---------------- | ------------ | -------- |
| dev     | debug            | text         | stdout   |
| staging | info             | json         | stdout   |
| prod    | warn             | json         | stdout   |

> **dev 環境のログフォーマット**: dev 環境では開発者の可読性を優先し `text` フォーマットを許容する（[helm設計.md](helm設計.md) の values-dev.yaml 参照）。staging / prod では JSON 構造化ログを必須とする。

### Go 実装例（slog）

```go
// internal/infra/config/logger.go
package config

import (
    "log/slog"
    "os"

    "go.opentelemetry.io/otel/trace"
)

func NewLogger(env, service, version, tier string) *slog.Logger {
    level := slog.LevelWarn
    switch env {
    case "dev":
        level = slog.LevelDebug
    case "staging":
        level = slog.LevelInfo
    }

    handler := slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{
        Level: level,
    })

    return slog.New(handler).With(
        slog.String("service", service),
        slog.String("version", version),
        slog.String("tier", tier),
        slog.String("environment", env),
    )
}

// トレースコンテキストをログに埋め込むミドルウェア
func LogWithTrace(ctx context.Context, logger *slog.Logger) *slog.Logger {
    spanCtx := trace.SpanContextFromContext(ctx)
    if spanCtx.HasTraceID() {
        return logger.With(
            slog.String("trace_id", spanCtx.TraceID().String()),
            slog.String("span_id", spanCtx.SpanID().String()),
        )
    }
    return logger
}
```

### Rust 実装例（tracing）

```rust
// src/infra/config/logger.rs
use tracing_subscriber::{fmt, EnvFilter, layer::SubscriberExt, util::SubscriberInitExt};

pub fn init_logger(env: &str) {
    let filter = match env {
        "dev" => "debug",
        "staging" => "info",
        _ => "warn",
    };

    tracing_subscriber::registry()
        .with(EnvFilter::new(filter))
        .with(
            fmt::layer()
                .json()
                .with_target(true)
                .with_span_events(fmt::format::FmtSpan::CLOSE),
        )
        .init();
}

// リクエストハンドラーでのトレース付きログ
#[tracing::instrument(
    skip(state),
    fields(
        service = "order-server",
        tier = "service",
    )
)]
async fn create_order(
    State(state): State<AppState>,
    Json(input): Json<CreateOrderInput>,
) -> Result<Json<Order>, AppError> {
    tracing::info!(
        method = "POST",
        path = "/api/v1/orders",
        "Processing create order request"
    );
    // ...
}
```

### ログ保持期間ポリシー

| 環境    | 保持期間 | 設定方法                            |
| ------- | -------- | ----------------------------------- |
| dev     | 7 日     | Loki `retention_period` で自動削除  |
| staging | 30 日    | Loki `retention_period` で自動削除  |
| prod    | 90 日    | Loki `retention_period` で自動削除  |

監査ログ（認証・認可関連）は通常ログとは別に長期保存する。

| ログ種別     | 保持期間 | 保存先                               |
| ------------ | -------- | ------------------------------------ |
| 監査ログ     | 1 年間   | Ceph オブジェクトストレージにアーカイブ |

```yaml
# Loki 保持期間設定例（prod）
limits_config:
  retention_period: 2160h  # 90日

# 監査ログ用の別テナント設定
overrides:
  audit:
    retention_period: 8760h  # 1年（365日）
```

### ログ集約（Loki）

```yaml
# Loki Stack (Promtail → Loki → Grafana)
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: observability
data:
  promtail.yaml: |
    server:
      http_listen_port: 3101
    positions:
      filename: /tmp/positions.yaml
    clients:
      - url: http://loki:3100/loki/api/v1/push
    scrape_configs:
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
            target_label: app
          - source_labels: [__meta_kubernetes_pod_label_tier]
            target_label: tier
        pipeline_stages:
          - json:
              expressions:
                level: level
                trace_id: trace_id
                service: service
          - labels:
              level:
              trace_id:
              service:
```

---

## 関連ドキュメント

- [tier-architecture.md](tier-architecture.md) — Tier アーキテクチャの詳細
- [kubernetes設計.md](kubernetes設計.md) — Namespace・NetworkPolicy 設計
- [インフラ設計.md](インフラ設計.md) — オンプレミスインフラ構成
- [サービスメッシュ設計.md](サービスメッシュ設計.md) — Istio 設計・耐障害性
- [config設計.md](config設計.md) — config.yaml スキーマと環境別管理
- [CI-CD設計.md](CI-CD設計.md) — CI/CD パイプライン設計
- [helm設計.md](helm設計.md) — Helm Chart 設計
- [メッセージング設計.md](メッセージング設計.md) — Kafka メッセージング設計
- [APIゲートウェイ設計.md](APIゲートウェイ設計.md) — API Gateway 設計
- [docker-compose設計.md](docker-compose設計.md) — ローカル開発環境の可観測性サービス設定
