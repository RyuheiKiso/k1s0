# サービスメッシュ設計

Istio によるサービスメッシュの詳細設計および耐障害性設計を定義する。
Tier アーキテクチャの詳細は [tier-architecture.md](../../architecture/overview/tier-architecture.md) を参照。

## 基本方針

- サービスメッシュは **Istio 1.24**（2024年末リリースの安定版）を採用する
- サービス間通信の暗号化（mTLS）を必須とする
- トラフィック制御（カナリアリリース・トラフィック分割）を Istio で管理する
- 耐障害性（Circuit Breaker・Retry）をアプリケーション外で統一的に設定する
- Istio Control Plane は `service-mesh` Namespace にデプロイする

---

## D-116: Istio 詳細設計

### VirtualService 設計

VirtualService でサービスへのトラフィックルーティングを定義する。

#### 基本ルーティング

> **注記:** 以下の order-server の例では timeout=10s, retry attempts=3 を設定しているが、これは service Tier のデフォルト値（timeout=15s, retry=2、「Tier 別デフォルト値」表を参照）をサービス固有の要件に基づいて意図的に上書きしたカスタマイズ例である。order-server は注文処理の特性上、より短いタイムアウトと多いリトライ回数が適切と判断している。各サービスは Tier デフォルト値を基本としつつ、業務要件に応じて個別に調整できる。

```yaml
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: order-server
  namespace: k1s0-service
spec:
  hosts:
    - order-server
  http:
    - route:
        - destination:
            host: order-server
            port:
              number: 80
      timeout: 10s          # service Tier デフォルト 15s を上書き
      retries:
        attempts: 3          # service Tier デフォルト 2 を上書き
        perTryTimeout: 3s
        retryOn: "5xx,reset,connect-failure,retriable-4xx"
```

#### カナリアリリース

```yaml
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: order-server
  namespace: k1s0-service
spec:
  hosts:
    - order-server
  http:
    - route:
        - destination:
            host: order-server
            subset: stable
          weight: 90
        - destination:
            host: order-server
            subset: canary
          weight: 10
```

#### ヘッダーベースルーティング

テスト用にヘッダーでルーティング先を切り替える。

```yaml
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: order-server
  namespace: k1s0-service
spec:
  hosts:
    - order-server
  http:
    - match:
        - headers:
            x-canary:
              exact: "true"
      route:
        - destination:
            host: order-server
            subset: canary
    - route:
        - destination:
            host: order-server
            subset: stable
```

### DestinationRule 設計

DestinationRule でサブセット定義とロードバランシングポリシーを設定する。

```yaml
apiVersion: networking.istio.io/v1
kind: DestinationRule
metadata:
  name: order-server
  namespace: k1s0-service
spec:
  host: order-server
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        h2UpgradePolicy: UPGRADE
        http1MaxPendingRequests: 100
        http2MaxRequests: 1000
        maxRequestsPerConnection: 10
    loadBalancer:
      simple: LEAST_REQUEST
    tls:
      mode: ISTIO_MUTUAL
  subsets:
    - name: stable
      labels:
        version: stable
    - name: canary
      labels:
        version: canary
```

### Gateway 設計とトラフィック経路

#### Nginx Ingress / Kong / Istio Gateway の役割分担

外部トラフィックの処理は3つのコンポーネントで段階的に行い、それぞれの責務を明確に分離する。

| コンポーネント            | 役割                                                     |
| ------------------------- | -------------------------------------------------------- |
| **Nginx Ingress Controller** | 外部トラフィックの入口（L7 ロードバランサー）、TLS 終端 |
| **Kong**                     | API Gateway としてのルーティング、認証、レート制限       |
| **Istio Gateway**            | Mesh 内部のトラフィック制御（カナリアリリース、フォールトインジェクション等） |

#### 外部トラフィックの流れ

```
Client → Nginx Ingress (TLS終端・L7 LB) → Kong (認証・レート制限・ルーティング) → Istio Sidecar (mTLS) → Backend Service
```

- **Nginx Ingress Controller** がクラスタ外部からのトラフィックを受け付け、TLS を終端する
- **Kong** が API Gateway として認証・認可・レート制限・ルーティングを担当する
- **Istio Sidecar** が Backend Service への通信を mTLS で暗号化する

#### Istio Gateway の使用方針

Istio Gateway は**外部公開には使用しない**。外部トラフィックの入口は Nginx Ingress Controller が担当する。

Istio Gateway は以下の Mesh 内部のトラフィック制御目的で使用する:
- VirtualService / DestinationRule によるカナリアリリースのウェイト制御
- フォールトインジェクションによる耐障害性テスト
- トラフィックミラーリング
- ヘッダーベースルーティング

```yaml
# Istio Gateway: Mesh 内部のトラフィック管理用
apiVersion: networking.istio.io/v1
kind: Gateway
metadata:
  name: k1s0-mesh-gateway
  namespace: service-mesh
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 443
        name: https
        protocol: HTTPS
      tls:
        mode: ISTIO_MUTUAL    # Mesh 内部通信のため mTLS を使用
      hosts:
        - "*.k1s0-system.svc.cluster.local"
        - "*.k1s0-business.svc.cluster.local"
        - "*.k1s0-service.svc.cluster.local"
```

### トラフィック制御

#### カナリアリリースの段階的ロールアウト（Flagger による自動判定）

カナリアリリースの自動化には **Flagger** を導入し、メトリクスに基づく自動判定でトラフィックウェイトを段階的に変更する。

| ステージ | 安定版 | カナリア | 評価期間 | 自動判定基準                                     |
| -------- | ------ | -------- | -------- | ------------------------------------------------ |
| 1        | 90%    | 10%      | 5 分     | エラーレート < 1% かつ P99 レイテンシ < 500ms     |
| 2        | 70%    | 30%      | 5 分     | エラーレート < 1% かつ P99 レイテンシ < 500ms     |
| 3        | 50%    | 50%      | 5 分     | エラーレート < 1% かつ P99 レイテンシ < 500ms     |
| 4        | 20%    | 80%      | 5 分     | エラーレート < 1% かつ P99 レイテンシ < 500ms     |
| 5        | 0%     | 100%     | -        | 完全切り替え（promotion）                         |

**ロールバック条件:**
- エラーレート > 5% の場合、即座にロールバック
- P99 レイテンシ > 1000ms の場合、即座にロールバック
- ロールバック時はトラフィックを 100% stable に戻し、canary Deployment を削除

```yaml
# Flagger Canary リソース定義
apiVersion: flagger.app/v1beta1
kind: Canary
metadata:
  name: order-server
  namespace: k1s0-service
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: order-server
  service:
    port: 80
    targetPort: 8080
    gateways:
      - mesh
  analysis:
    interval: 5m
    threshold: 2          # ロールバックまでの連続失敗回数
    maxWeight: 80
    stepWeight: 20        # 10 → 30 → 50 → 80 の段階で増加（初期値 10 + stepWeight 20）
    metrics:
      - name: request-success-rate
        thresholdRange:
          min: 99          # エラーレート < 1%（成功率 > 99%）
        interval: 5m
      - name: request-duration
        thresholdRange:
          max: 500         # P99 レイテンシ < 500ms
        interval: 5m
    webhooks:
      - name: rollback-alert
        type: rollback
        url: http://alertmanager.observability.svc.cluster.local:9093/api/v1/alerts
```

#### トラフィックミラーリング

本番トラフィックのコピーを新バージョンに送信し、レスポンスを検証する（ユーザーには影響しない）。

```yaml
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: order-server
  namespace: k1s0-service
spec:
  hosts:
    - order-server
  http:
    - route:
        - destination:
            host: order-server
            subset: stable
      mirror:
        host: order-server
        subset: canary
      mirrorPercentage:
        value: 10.0
```

### Timeout / Retry ポリシー

#### Tier 別デフォルト値

| Tier     | Timeout | Retry 回数 | perTryTimeout | retryOn                              |
| -------- | ------- | ---------- | ------------- | ------------------------------------ |
| system   | 5s      | 3          | 2s            | `5xx,reset,connect-failure`          |
| business | 10s     | 3          | 3s            | `5xx,reset,connect-failure`          |
| service  | 15s     | 2          | 5s            | `5xx,reset,connect-failure,retriable-4xx` |

#### system Tier のデフォルト

```yaml
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: default-system
  namespace: k1s0-system
spec:
  hosts:
    - "*.k1s0-system.svc.cluster.local"
  http:
    - route:
        - destination:
            host: "*.k1s0-system.svc.cluster.local"
      timeout: 5s
      retries:
        attempts: 3
        perTryTimeout: 2s
        retryOn: "5xx,reset,connect-failure"
```

### mTLS 設定

すべてのサービス間通信で mTLS を強制する。

**メッシュワイドデフォルト（Istio Control Plane Namespace）:**

`service-mesh` Namespace（istiod のデプロイ先）に PeerAuthentication を定義し、メッシュ全体のデフォルトとして STRICT mTLS を強制する。

**防御多層化:** メッシュワイドデフォルトに加え、各 Tier の Namespace にも個別の PeerAuthentication を定義している（[認証認可設計.md](../../auth/design/認証認可設計.md) の「サービス間認証 mTLS」セクション参照）。メッシュワイド設定が誤って変更された場合でも、Namespace レベルの設定が防御層として機能する。

```yaml
# メッシュワイドデフォルト（service-mesh = istiod の Namespace）
apiVersion: security.istio.io/v1
kind: PeerAuthentication
metadata:
  name: default
  namespace: service-mesh
spec:
  mtls:
    mode: STRICT

---
# observability Namespace は PERMISSIVE（Prometheus の scrape を許可）
apiVersion: security.istio.io/v1
kind: PeerAuthentication
metadata:
  name: allow-prometheus
  namespace: observability
spec:
  mtls:
    mode: PERMISSIVE
```

### AuthorizationPolicy

Tier 間のアクセス制御を Istio AuthorizationPolicy で強制する。AuthorizationPolicy の詳細定義（`allow-from-lower-tiers`, `allow-from-service-tier`, `allow-from-ingress`, `deny-bff-to-bff` 等）は [認証認可設計](../../auth/design/認証認可設計.md) を参照。

---

## D-118: 耐障害性設計

### Circuit Breaker

Istio の DestinationRule で outlierDetection を設定し、異常なインスタンスを自動的に除外する。

#### Tier 別デフォルト値

| 設定                      | system  | business | service |
| ------------------------- | ------- | -------- | ------- |
| consecutive5xxErrors      | 3       | 5        | 5       |
| interval                  | 10s     | 30s      | 30s     |
| baseEjectionTime          | 30s     | 30s      | 60s     |
| maxEjectionPercent        | 30      | 50       | 50      |

#### system Tier の Circuit Breaker

```yaml
apiVersion: networking.istio.io/v1
kind: DestinationRule
metadata:
  name: auth-server
  namespace: k1s0-system
spec:
  host: auth-server
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 200
      http:
        http1MaxPendingRequests: 200
        http2MaxRequests: 2000
        maxRequestsPerConnection: 20
    outlierDetection:
      consecutive5xxErrors: 3
      interval: 10s
      baseEjectionTime: 30s
      maxEjectionPercent: 30
    tls:
      mode: ISTIO_MUTUAL
```

#### service Tier の Circuit Breaker

```yaml
apiVersion: networking.istio.io/v1
kind: DestinationRule
metadata:
  name: order-server
  namespace: k1s0-service
spec:
  host: order-server
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 100
        http2MaxRequests: 1000
        maxRequestsPerConnection: 10
    outlierDetection:
      consecutive5xxErrors: 5
      interval: 30s
      baseEjectionTime: 60s
      maxEjectionPercent: 50
    tls:
      mode: ISTIO_MUTUAL
```

### Retry + Exponential Backoff

Istio VirtualService の retry 設定で自動リトライを行う。Exponential Backoff は Envoy のデフォルト動作（25ms ベース + ジッター）に従う。

```yaml
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: order-server
  namespace: k1s0-service
spec:
  hosts:
    - order-server
  http:
    - route:
        - destination:
            host: order-server
      retries:
        attempts: 3
        perTryTimeout: 3s    # 基本ルーティングの order-server 設定と統一
        retryOn: "5xx,reset,connect-failure,retriable-4xx"
        retryRemoteLocalities: true
```

### Retry 対象の判定基準

| 対象               | リトライ | 理由                                |
| ------------------ | -------- | ----------------------------------- |
| 5xx                | Yes      | サーバー側の一時的なエラー          |
| connect-failure    | Yes      | ネットワーク接続失敗                |
| reset              | Yes      | 接続リセット                        |
| retriable-4xx      | Yes      | 409 Conflict 等の一時的な 4xx       |
| 400 Bad Request    | No       | クライアント側のリクエスト不正      |
| 401/403            | No       | 認証・認可エラー                    |
| 404 Not Found      | No       | リソースが存在しない                |

### フォールト インジェクション（テスト用）

staging 環境で障害をシミュレートし、耐障害性を検証する。

#### 実行方針

| 項目           | 内容                                                                 |
| -------------- | -------------------------------------------------------------------- |
| 実行環境       | staging 環境のみ                                                     |
| 実行スケジュール | 毎週月曜日 10:00 JST にスケジュール実行（CronJob で管理）            |
| 対象           | 全サービス間通信                                                     |
| レイテンシ注入 | 500ms の遅延を 10% のリクエストに注入                                |
| HTTP フォルト  | 503 エラーを 5% のリクエストに注入                                   |
| 結果可視化     | Grafana ダッシュボード（`Fault Injection Results`）で可視化          |
| レポート       | 週次レポートとして結果を集計し、Teams の `infra-report` チャンネルで共有 |

#### レイテンシ注入

```yaml
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: order-server-fault-test
  namespace: k1s0-service
spec:
  hosts:
    - order-server
  http:
    - fault:
        delay:
          percentage:
            value: 10.0
          fixedDelay: 500ms
      route:
        - destination:
            host: order-server
```

#### HTTP フォルト注入

```yaml
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: order-server-abort-test
  namespace: k1s0-service
spec:
  hosts:
    - order-server
  http:
    - fault:
        abort:
          percentage:
            value: 5.0
          httpStatus: 503
      route:
        - destination:
            host: order-server
```

#### スケジュール実行用 CronJob

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: fault-injection-test
  namespace: k1s0-service
spec:
  schedule: "0 1 * * 1"    # 毎週月曜日 10:00 JST（UTC 01:00）
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: fault-injection
              image: bitnami/kubectl:latest
              command:
                - /bin/sh
                - -c
                - |
                  # フォールトインジェクション VirtualService を適用
                  kubectl apply -f /config/fault-delay.yaml
                  kubectl apply -f /config/fault-abort.yaml
                  # 30分間テストを実行
                  sleep 1800
                  # テスト終了後にフォールトインジェクションを削除
                  kubectl delete -f /config/fault-delay.yaml
                  kubectl delete -f /config/fault-abort.yaml
              volumeMounts:
                - name: config
                  mountPath: /config
          volumes:
            - name: config
              configMap:
                name: fault-injection-config
          restartPolicy: OnFailure
```

#### Grafana ダッシュボード

フォールトインジェクション結果を可視化するための Grafana ダッシュボードには以下のパネルを含める:

- **エラーレート推移**: フォールト注入前後のエラーレートの変化
- **P99 レイテンシ推移**: レイテンシ注入によるレスポンスタイムへの影響
- **Circuit Breaker 発動状況**: outlierDetection による Pod 除外の発生回数
- **リトライ回数**: Envoy のリトライ発生回数と成功率

---

## 関連ドキュメント

- [tier-architecture.md](../../architecture/overview/tier-architecture.md) — Tier アーキテクチャの詳細
- [kubernetes設計.md](../kubernetes/kubernetes設計.md) — Namespace・NetworkPolicy 設計
- [インフラ設計.md](../overview/インフラ設計.md) — オンプレミスインフラ構成
- [APIゲートウェイ設計.md](../../api/gateway/APIゲートウェイ設計.md) — Kong 構成管理
- [可観測性設計.md](../../observability/overview/可観測性設計.md) — 監視・ログ・トレース設計
- [helm設計.md](../kubernetes/helm設計.md) — Helm Chart と values 設計
- [terraform設計.md](../terraform/terraform設計.md) — Terraform モジュール設計
- [認証認可設計.md](../../auth/design/認証認可設計.md) — 認証・認可・AuthorizationPolicy
- [メッセージング設計.md](../../architecture/messaging/メッセージング設計.md) — Kafka メッセージング設計
